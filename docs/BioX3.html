

<style>

</style>

<div id="fig_el229181397327242536968160816196"></div>
<script>
function mpld3_load_lib(url, callback){
  var s = document.createElement('script');
  s.src = url;
  s.async = true;
  s.onreadystatechange = s.onload = callback;
  s.onerror = function(){console.warn("failed to load library " + url);};
  document.getElementsByTagName("head")[0].appendChild(s);
}

if(typeof(mpld3) !== "undefined" && mpld3._mpld3IsLoaded){
   // already loaded: just create the figure
   !function(mpld3){
       
       mpld3.draw_figure("fig_el229181397327242536968160816196", {"data": {"data01": [[-0.10727242110819896, 0.056034466145307514], [-0.07767835522244931, -0.09371481278955099], [-0.0978237344576451, -0.08610370839997071], [-0.08691738313930335, -0.1612744533027579], [0.06861634964219782, -0.3327102476236188], [0.020462534824250842, -0.4052525062545243], [-0.04734683620069103, -0.2562199599830677], [-0.10182530593700469, 0.24268587970419536], [-0.07454360655456688, 0.10902708164934788], [-0.10138776781660104, 0.0012276187378888383], [-0.14397282706377795, 0.024980503818468617], [-0.06444760248637746, -0.02862344281074209], [-0.08433577114722553, 0.004471942212242875], [-0.1309294266637809, 0.023154881178064607], [-0.07568325588702912, 0.011378336917657758], [-0.02835991476525087, -0.08070278843722838], [-0.09874485256048857, -0.01122241255566899], [-0.09874485256048864, -0.011222412555669017], [-0.08812683544786963, -0.006108476423168935], [-0.17316814130533137, 0.1307711669369488], [-0.17247767029974898, 0.12238526531420814], [-0.13974407350726717, 0.08141205644887091], [-0.14989424790272515, 0.2532806138356442], [-0.07908288903702676, 0.2037002494758532], [-0.12278427807302474, 0.014655055991681992], [-0.119096562485101, 0.01248403253981233], [0.020326304544425165, -0.28479139768262945], [0.00579456757619414, -0.12107380365748166], [-0.08231125355502475, 0.02966881097084069], [-0.05087578967534923, -0.09164913657227229], [0.050378143880776466, -0.17921831634466712], [-0.0929396796138604, -0.04652841400054207], [-0.05662725301152238, -0.10257948753039688], [-0.1309294266637809, 0.023154881178064565], [-0.1208914948530424, 0.01684611185017089], [-0.0911848498413192, -0.005111871395159533], [-0.1503684346427546, 0.4188142074888131], [-0.07540571148337409, 0.054827013588195826], [-0.035604387651408526, -0.2772416871366358], [-0.06647566199977781, -0.02741099491654421], [-0.12277757820114901, -0.0830164906591825], [-0.055756589590237896, -0.22160829245736074], [-0.10165953721554193, -0.020218186525082907], [0.0281998668847653, -0.25403166603415517], [0.04476629712105019, -0.4193913731552902], [-0.0958199240859659, 0.07875595154982604], [-0.042345947578282, -0.18572854695236743], [0.004664622448618803, -0.2514536840310804], [-0.0680439606634897, -0.13867882084924563], [0.4259417842645283, -0.21758005709446757], [-0.01697605460961052, -0.1765096131686985], [-0.1422209522943006, 0.20254861140087005], [0.012333595206254315, -0.2746531332753382], [-0.08324637829561694, 0.09569131669632597], [-0.007708497996513715, -0.2794299609830357], [-0.02360488800798698, -0.22298066223219382], [-0.09546380497381031, -0.08866860018078537], [0.029896123788976367, -0.10081490139792643], [-0.09493187650362522, -0.0078043508936891], [-0.21076886830808403, 0.45567277273550155], [-0.12303681517110253, -0.05108015225825407], [0.07469717593723543, -0.11228152133563582], [0.5947508332026333, 0.21588077071863734], [-0.10870580744896648, -0.1513503405668154], [-0.08356047354412158, 0.11284097989096754], [-0.09657373586303422, -0.21589185219208], [-0.0506151934706682, -0.339445817645953], [-0.07175507801076082, -0.06651727509431667], [0.008943821895630354, -0.08497654183786098], [-0.1087058074489665, -0.1513503405668154], [-0.09545061623281982, -0.06628707727125276], [-0.12516379982454034, -0.034175893409573485], [-0.11523684887518605, -0.008701037522590488], [-0.17536595654468357, 0.5360825663045121], [-0.17536595654468365, 0.5360825663045121], [-0.16261343440647455, 0.4439700188855954], [-0.09210844256778558, 0.049248319267324564], [-0.09543866555157351, 0.0499176760007965], [-0.08891958319079712, 0.04557302979206468], [-0.03816952336861682, -0.1119368414468306], [-0.12214959572013558, -0.010598505212340438], [-0.04775269252569938, -0.11520554186999407], [-0.0835852719170874, 0.5263295059978612], [-0.039216984367689854, -0.11678860656719997], [-0.10525170492027608, 0.1756266001913818], [-0.07282658494847785, -0.22741101813509831], [-0.1251185356778328, -0.1556817158046111], [0.2437863442768604, 0.11619932297175162], [-0.09187093612880828, 0.02932137339818053], [-0.10443960458567873, 0.06216005502350786], [-0.16822232801012665, 0.3808437469933286], [-0.08005073586492858, 0.0663230562842798], [-0.11330299783230699, -0.15428356869833562], [-0.05705262551759115, -0.30509362877735374], [-0.08618886102424125, 0.13305188088888906], [0.6355186445607468, 0.005168544107673091], [0.7743535206282145, -0.0800316461984685], [0.4173927827199395, -0.04236383955396936], [0.71506549507598, -0.10431073730256865], [-0.06939220758403612, -0.12224266337564357], [-0.08432378030687969, -0.06648903478004169], [-0.11330299783230693, -0.15428356869833576], [-0.08630323401987747, -0.11699305539250862], [-0.02179585265157594, -0.2899871415663814], [0.32632199690626457, 0.36893761425915694], [0.4538765865809893, 0.2807583750722457], [-0.0964844829409978, 0.029921792832450073], [-0.1399574288465819, 0.13810596944588777], [0.6835381107205909, -0.07057017052292087], [0.7302469646278138, 0.0691210389768199], [-0.09060468878350333, 0.10352275179875504], [0.6895934638092436, -0.16441377097970084], [-0.03548859719155889, -0.09221175973127024], [-0.105251704920276, 0.17562660019138177], [-0.09208321913152809, -0.17836293923188254], [-0.20139647121090978, 0.6766069510948846], [-0.1479508057806757, 0.34899243162967397], [-0.17050849074821467, 0.45849460790470614], [-0.08358527191708742, 0.5263295059978613], [-0.10617374190240998, -0.048089298811109], [-0.02261875797695372, -0.05688718102191002], [-0.12926118666513411, -0.07571138445097629], [-0.0008171648004735801, -0.06788772733711064], [-0.08957200309419978, 0.08525395287656129], [-0.04650483476473082, -0.05390457770629112], [-0.07701351549043492, 0.14194523058608333], [-0.11861161143762271, -0.11589398143117365], [-0.08794675374543778, 0.07002078319517595], [-0.09220756553219878, 0.050602261525988644], [0.7045522044021921, 0.2784168052583952], [-0.10656978516320055, 0.052903132998516754], [0.7045522044021922, 0.27841680525839524], [0.7045522044021922, 0.27841680525839524], [-0.09101237185799595, 0.09209052079244932], [-0.12043995800400602, 0.01422682742676336], [0.01712307057999428, 0.10232630416452013], [-0.09414642750543399, -0.021918995452943613], [-0.08278090438070876, 0.0773037382073881], [0.30616718854934655, 0.0012406372013222377], [-0.0659243732370409, -0.09492799813832493], [-0.07839960833753436, -0.19739056645473776], [-0.08904678916024408, -0.050185264944005416], [-0.08243620588887964, -0.015559858724626379], [-0.17034628364311002, 0.1904928612444531], [-0.07868726677739138, -0.03407793941013253], [-0.11635513166282702, 0.12262847906023745], [-0.07688540575835495, 0.1158132654047259], [-0.1342422274628025, 0.06087211623705313], [0.7735441987928864, 0.270335465601552], [0.8069829116565443, 0.11716714061509095], [-0.025583947144065464, -0.3509410091161083], [-0.10718185167941129, -0.06949656513505865], [0.007700126164142015, -0.1583448734590568], [-0.09546380497381031, -0.08866860018078536], [0.21175637076687379, -0.29612256672049014], [0.6988893557780519, 0.05582709769867708], [0.013766150339171137, -0.24578335284767344], [-0.14587866623254517, 0.1512248308982449], [-0.00724509912790304, -0.259077444693641], [-0.053440350818153924, -0.12146259540453364], [-0.07896939382744605, -0.06267148582937929], [-0.11571708498923118, 0.06145799897899285]]}, "height": 1080.0, "plugins": [{"type": "reset"}, {"type": "zoom", "enabled": false, "button": true}, {"type": "boxzoom", "enabled": false, "button": true}, {"hoffset": 0, "id": "el22918139732732171992", "location": "mouse", "type": "tooltip", "voffset": 10, "labels": ["Hi for the take a look as we bring nodes back online after the Kilian", "did find one node which had unmounted the and I disabled that I would have expected some kind of not message or something", "Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine On Jun at Alex Chekholko A number of compute nodes on are down with hardware so these jobs have I will purge them from the output in a few ACTIVE JOBNAME USERNAME STATE PROC REMAINING STARTTIME rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May Running Wed May Running Wed May Running Wed May rhiju Running Wed May Running Wed Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun Running Fri Jun Alex Chekholko", "forced the deletion of the problematic I rebooted a couple of the nodes including and they are down with some hardware", "please let us know if you need anything", "Hi rebooted that node and another Please let us know if you have any other", "Hi Thank you for your I relaunched some I still see my jobs from before running and all the new in the I know if there are no more nodes available should get instead of but at least the queue is let you know if I experience anything weird going Johan", "Thank you this is much Kilian", "Hi The accounts have been removed from both and and the associated data Kilian", "Hi the filesystem is full on despite the numerous warnings sent in the As a jobs will fail and application will generate errors until the situation is rules are in place to make sure usage is equally shared between groups and and prevent situation where a single user could monopolize the whole Kilian", "that was Things are looking Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Mark you have emailed me times about Can you I said I am not having issues", "the problem is that the most recent GCC version that the distribution provides is There is also a version you can try in if it work I would suggest trying to compile a newer GCC in your home Kilian", "I will not be monitoring consistently through the Please expect delays in response until Rhiju Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Hi Thanks for your patience while resolving The filesystem is back in finishing troubleshooting a few compute Filesystem access should be working normally from the login Please let us know if you notice any Kilian", "Hi The filesystem on experienced some We believe they are resolved so you should be able to log in without any Please let us know if you still experience any Kilian", "Hi We think the issue was that the filesystem was mostly full in terms of inodes such as files or As a any process creating a lot of small such as a was generating a huge load on the metadata which was in turn struggling to allocate new objects in a very constrained That load very likely was the reason why the filesystem seemed really slow at Some cleanup had been done on the filesystem still need to be so if you have files that you really need on please hesitate to remove and we think that the issue should be solved for Kilian", "Hi We think the issue was that the filesystem was mostly full in terms of inodes such as files or As a any process creating a lot of small such as a was generating a huge load on the metadata which was in turn struggling to allocate new objects in a very constrained That load very likely was the reason why the filesystem seemed really slow at Some cleanup had been done on the filesystem still need to be so if you have files that you really need on please hesitate to remove and we think that the issue should be solved for Kilian", "Thank you very much for your Kalli", "Thanks very Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Things are getting progressively better we were quite anxious over the weekend many thanks for your Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Hi thanks for the I have been doing calculations and everything has been I guess I should not have been trying to do calculations over Paul Ruijgrok Postdoctoral Scholar in Bryant Molecular Motors Lab email lab phone Web Mailing and visiting Stanford University Department of Bioengineering VIA ORTEGA BioEngineering CA", "I can kill them thanks Zheng", "Hi this is more information about is available at Kilian", "connected thank you so Paul Paul Ruijgrok Postdoctoral Scholar in Bryant Molecular Motors Lab email lab phone Web Mailing and visiting Stanford University Department of Bioengineering VIA ORTEGA BioEngineering CA", "Paul Ruijgrok Postdoctoral Scholar in Bryant Molecular Motors Lab email lab phone Web Mailing and visiting Stanford University Department of Bioengineering VIA ORTEGA BioEngineering CA", "We have an easy way to roll that software out on so just do it on the login node Please let us know if you have any Alex", "Hi find your compiled version in Please give it a try and let us know how it Kilian", "you should probably remove About the temporarily you had thousands of processes running on the login probably a fork loop gone I killed You should be able to connect Kilian", "Hi how come you set But you request only cores from the So this job runs iterations of an osprey Or it launcher simultaneous instances of Alex", "Sorry for the feel free to drop those I rebooted a couple of compute nodes that ended up in a weird state and also contacted the Alex", "seeing this same problem again on Would it be possible to try restarting the scheduler Kalli", "Hi Sorry for the I changed our script to restart the scheduler twice a day instead of once a see what happens It is set to automatically restart at and at Alex", "I am out of town with family and will not be monitoring consistently through the end of Please expect delays in response until Rhiju Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Thank Sabina Sood Stem Cell Biology Candidate Gerald Crabtree Lab Stanford Medical School", "Hi Thank I am able to log in through sherlock and then which works well for Han Han Institute of Candidate in Biological", "HI Thanks for much I guess go the hard reset Kilian", "Hi Your group is actually pretty good on that your aggregated usage is about which is far less than the biggest individual And by the there is not much alternatives in terms of storage as on and are actually the same Kilian", "I disabled and rebooted that sorry for the Alex", "I appreciate your help resolving this The program runs Matias", "Hi On as a member of an owner you would be able to submit jobs to the partition and effectively get access to every single node on Sherlock as of which is way more than a all jobs submitted to the owners partition are subject to That if the owners of the nodes your jobs are running on needs their your jobs will be killed and Some applications can resume from where they left some and need some cleanup to be able to but besides some this could be a great way to get access to massive amounts of computing Kilian", "Hi Sorry for the I see there was a problem with the scheduler on I restarted it and job reporting is OK I see a job for you either running or so maybe your job already Please let us know if you have any other Alex", "Thank Amanda Miguel Sent with Airmail", "We resolved the issue with the filesystem on Please let us know if you encounter any other Alex", "I rebooted that Please let us know if you see any other", "Sorry about this and for the I am on it and should be able to delete at least some of the stuff on here Steven On Apr at Kilian Cavalotti Hi currently the top user in terms of storage space used in the with more than If you could please do some cleanup and remove files you need that would be Kilian", "Hi I restarted the Please try Sorry for the Alex", "Hi I went ahead and disabled that node and will reboot it and take a closer Please let us know if you have any other Alex", "Hi I see there are a lot of jobs on the but I see any jobs from Are you still having any Alex", "Hi I created your account on You can find more info Please let us know if we can be of any more Alex", "Hi Jupyter is a so I think most people install and update it I can recommend the Anaconda python distribution which installs into your homedir and updates And require any sysadmin So I recommend you use Please let us know if we can be of any more Alex", "thanks very much it does appear to be working Joe", "Hi Not sure about your login but it looks like been able to log in since through another If you even ping something is wacky about either your local DNS or your local network If you still have connectivity problems let me know the host from which connecting and we can figure it Please let us know if we can be of any more Alex", "I just killed the it send emails Cheers Kilian", "Hi It looks like is not available for our older version of We currently have any plans to upgrade on Sorry for the Please let us know if we can be of any more Alex", "Hi take a That cluster is overdue for so some nodes are misbehaving Alex", "I Vijay Sent from my Sorry for the brevity or unusual", "Let me know if you still encounter Kilian", "Hi It would indeed be better to submit a job to do You can launch an interactive job in a session if you want to be able to interact with your Something qsub waiting for job to start job ready This you can detach your screen session and reconnect to it later with on the login Kilian", "I Thanks very much for the Wen", "Hi Do you have a way to break up your jobs into smaller chunks so that they finish in under I think it was the cluster PIs who wanted to bump down the time I see we sent a note to on June Dear Due to the recent trend of increasing wait times in scheduler modified some in order to lower the barrier of entry for users who constantly submit As of the following modifications come into the maximum number of CPUs any given user can use at once is the default walltime limit for jobs is and the maximum that can be requested is a new QOS is introduced that could allow to exceed the CPUs limit when the cluster is This QOS makes jobs meaning that they can be killed and requeued if resources are requested from other To use that one can use the submission as The immediate effect will be that more resources should be kept available for monitor the state of the queue for the next few days to see if the situation improves and if adjustments are Kilian", "Let us know if we can be of any more Kilian", "Hi Your account on has been You can SSH with your SUNetID credentials to Check out the wiki page for more Kilian", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy DNS On November the legacy DNS service will be Please update the DNS configuration on your node or nodes to use the anycast DNS service as described Here is a list of your nodes that queried the legacy DNS service on Monday", "maybe the previous email stream ending and the last emails being Kilian", "Hi Sorry about a couple of nodes crashed and I forgot to disable them before rebooting and your jobs got sent to them immediately as they came but before they mounted the shared So the jobs errored Please resubmit and Alex", "Sorry about a few nodes and we rebooted them go do that Alex", "Hi the limit on the maximum number of CPUs per user was applied to all including the background That should be fixed Note that still a limit on the number of CPUs usable with the background so we can still keep resources available for but much higher than in the default So I believe the problem is fixed And I think the job defaulting to the NORMAL QOS Please try and let me know if you still see any Kilian", "No Let me know if you notice anything unexpected under the new Kilian", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy DNS On November the legacy DNS service will be Please update the DNS configuration on your node or nodes to use the anycast DNS service as described Here is a list of your nodes that queried the legacy DNS service on Monday", "Note that disk the whole filesystem goes I suggest we do this by CPU usage not file system usage since there will be no CPU usage a Vijay Sent from my Sorry for the brevity or unusual", "Hi was efficient or and I have the It ran with and one process per did not produce any out put after more than I killed It ran without and one process per node So far I understand I should run with less processes per even if this is not and use Thank Yana Yana Gofman Postdoctoral Fellow Michael Levitt Lab Department of Structural Biology Stanford University School of Medicine James Clark Center Campus Room CA", "Hi This is indeed what I eventually did but I also had to do Not sure but it did not work thought that if I ask each process uses of it should be and fits the machine but somehow it did not work this thank you very Yana Yana Gofman Postdoctoral Fellow Michael Levitt Lab Department of Structural Biology Stanford University School of Medicine James Clark Center Campus Room CA", "Hi No Thanks for your effort and for your this is much Kilian", "Hi Thanks for your effort and for your this is much Kilian", "Hi Thanks a lot for your effort and your this is much Kilian", "Hi a few days is perfectly We just want to make sure that all the and obsolete files are cleaned up so room can be made for more useful Kilian", "Hi for getting back to and for your cooperation in that can keep as much as you We just want to make sure that all the and obsolete files are cleaned up so room can be made for more useful Kilian", "Hi Those failures were caused by the local disk being full on some of the compute I did some cleanup so it should be better And I believe the errors you had on were caused by the same Kilian", "I ended up just killing old processes from people not logged in that are more than a week Alex", "Just running basic commands seemed abnormally but now working much Erik Erik Postdoctoral Scholar Gerald Crabtree Lab Stanford University", "Hi I think usually that means that the kernel killed that usually because it used up all the system Do you know how much memory your program Perhaps the memory usage varies with input data or some Alex", "Should be back in business Kilian", "Hi I power cycled look for them to come back up in a couple of Alex", "Hi I restarted the it should come back Kilian", "Some of the nodes I rebooted them and your old jobs Consider requesting more memory for your in case they ran out of Alex", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still attempting to use the legacy NTP service even though been turned Please consider updating the NTP configuration on your nodes to use the current NTP service as described Make sure to restart the NTP process reboot the so it uses the new Here is a list of your nodes that need to be updated", "Hi I created your account on You can connect the the login node with Please see for more Kilian", "I found the following on the Out of Kill process process UID So you could try to reduce the total number of processes as well as the number of processes per Kilian", "Hi not completely but quite Definitely very rebooted it should come back online Kilian", "Hi Thanks for the The Maui scheduler That should be better Kilian", "Hi not sure what you mean by Your state is which means eligible to run and will start as soon as enough resources are Kilian", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy NTP service that was replaced years On May the systems providing the legacy NTP service will no longer respond to NTP Please update the NTP configuration on your nodes to use the current NTP service as described Here is a list of your nodes that need to be", "Hi Looks like you submitted a bunch of jobs with small resource they all ended up scheduled to the same physical and that node crashed after maybe running out of I went ahead and rebooted that Maybe adjust your resource requests per job up a Please let us know if we can be of any more You can use the command to see your Alex", "Hi Thanks for the Alex was able to provide what we", "I created the vineetk account on Check out the wiki link for more Alex", "Hi I created your account on You can SSH with your SUNetID Check out the wiki link in the motd for more Please let us know if we can be of any more Alex", "I added the account for enf on More info at the wiki and in the Alex", "Hi I created your account on You can SSH to with your SUNetID a link to the wiki in the Please let us know if we can be of any more Alex", "I removed many TBs Hopefully this is enough Matt Original Message Computing March AM Filesystem usage on Hi currently using about on which makes you the largest consumer of storage resources on that Since the filesystem starts to fill we would appreciate if you could do some cleanup in your old remove the ones you need and maybe transfer out the ones you want to keep on the longer Please let me know if you have any Research Computing Support", "Thanks for the clean some stuff up over the On March Research Computing Support Hi currently using on which makes you the largest consumer of storage resources on that Since the filesystem starts to fill we would appreciate if you could do some cleanup in your old remove the ones you need and maybe transfer out the ones you want to keep on the longer Please let me know if you have any Research Computing Support Sent from my", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy NTP service that was replaced years On May the systems providing the legacy NTP service will no longer respond to NTP Please update the NTP configuration on your nodes to use the current NTP service as described Here is a list of your nodes that need to be", "Thanks for the Will keep it in mind in the Steven On Feb at Alex Chekholko Looks like a lot of these jobs are so likely they are running slower than you sryckbos Ss sryckbos S sryckbos Dl worker sryckbos Dl worker sryckbos Rl worker sryckbos Dl worker sryckbos Dl worker sryckbos Dl worker On Alex Chekholko I was looking around at some compute and I see your osprey jobs sometimes run out of memory and get Out of Kill process score or sacrifice child Killed process UID You may want to request more memory for those Alex Chekholko", "Hi I took a look at that jobid and it looks like there is some minor problem with one compute disabled that compute node and will take a closer Please let us know if you see any other Alex", "Hi Your account on has been Kilian", "Hi I created your account on Kilian", "Hi GCC is installed on node You can use it scl enable bash posixgcc version Hat Kilian", "Thanks working great Nir Nir of Biological Chemistry The Silberman Institute of Life Sciences The Hebrew University of Jerusalem Lab", "Hi I created your account on You can SSH with your SUNetID credentials to Check out the wiki page for more Please let us know if you need anything Alex", "Hi I created your account on You can SSH to with your SUNetID so your username is Check out the wiki for more Alex", "Hi Matlab is not installed on You can use it on Farmshare see for Kilian", "I created your account on Check out the wiki for more Please let us know if you have any Alex", "Accounts are always mapped to On we use Unix groups to group people by their Alex", "Hi I restarted those they should come back Kilian", "Hi I see you have two jobs listed and each is on a crashed nodes and go reboot those and you should see those jobs Alex", "Hi Thanks for letting me Kilian", "Hi Reboot is thanks for reporting Kilian", "Hi Thanks for the the reboot is Kilian", "No On we have and Kilian", "Hi I took the example of job It runs on as well as job ids to all of which are Those processes seem indeed all be stuck on something as they use any CPU time at all on the Looking in more it looks like stuck on some sort of the backtrace for one of gstack in from in from in from in fork from in from in from handler in from in malloc from in in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in in in in in in in in main From that trace it looks like the process received a signal forked and then is now waiting on a Does that sound familiar to you regarding the Do you now what kind of signal the application may have Kilian", "Hi This fixed our are not using python scripts in the jobs but they may otherwise make use of the abrt socket check the source Rosetta And abrt adds a new exception handler that overrides the default See let the rest of my lab know that fixed the And as per your other send a note to the mailing Kilian", "Hi Thanks for the detailed Looking at your idle processes on that specific it looks like they were stuck on connecting to the abrt abrt is a to help users to detect defects in applications and to create a bug report with all informations needed by maintainer to fix I think you were using it on purpose me if but since it provides python bindings which may be active by likely that the python scripts in your jobs were using there seems to be a bug with so I removed it from the compute And it looks like it even unblocked your previously idle Let me know if it really fixes your Kilian On Rhiju Das Hi Thanks for helping set up the two new users from my lab so We had one more question seen this in the but now its getting a little I will often kick off and see them as running but then they never actually use any CPU time or do After the wall time is they are This has not been mission critical for the last few but is about to be a big pasting below an example of such a zombie job running right now On the same node there are four other jobs from me that are running fine which I can see via but this and its sisters are not going No one else seems to be running on that I tried to reduce the declared memory to the default of but that Any advice would be We want to be the ones tying up the queue with zombie Rhiju qstat Job R queue SP server Checkpoint u ctime Fri Sep n n n n mtime Fri Sep Priority qtime Fri Sep Rerunable True etime Fri Sep Fri Sep False", "No Let me know if it changes things for Kilian", "Hi Nice to Regarding I think it can be used on without a But installed and licensed on Farmshare and Kilian", "Hi The memory usage of a job at some point in time is not always representative of its peak So maybe on the nodes the jobs were not using all the memory they requested at that specific but perhaps they will need it gonna check with the see if intended an what his real usage Kilian", "Hi The NVIDIA kernel module was not loaded correctly on that It should be fixed Kilian", "Hi I restarted the and it looks like the runaway jobs have Regarding the high number of jobs as Alex explained due to the nature of the jobs currently If you run see that most nodes that have cores available have very little memory in any case not enough to run the jobs that are There are a few nodes for which the scheduler state does not match their real load probably because of runaway gonna take care of but it change much regarding the pending Kilian", "Hi The node crashed and failed to remount the directory at fixed Kilian", "Hi has been rebooted and should be back online And I deleted your Kilian", "Hi account has been You can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "Hi was indeed overloaded with user processes and partially rebooted the it should come back online Kilian", "Hi account has been You can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "Hi Your account has been can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "No And sorry we have a more recent Kilian", "Erik Miller Candidate Department of Genetics Gerald Crabtree Lab Stanford University", "Thanks you should be able to log in with your normal Stanford username and with ssh Here is the wiki for During our next go over how to submit jobs on this awesome Best Alexandre Alexandre Colavin Biophysics PhD Candidate Huang Lab Stanford University", "Hi We do not handle the billing for use of that is managed through the I would recommend you contact Levitt and To my only the PIs who are entitled to use the I do not see Weis in that Pande Levitt Altman Huang Das Bryant Crabtree Guibas Covert Darve Martinez Kornberg When did you get an Were you working with another Ruth", "Hi Glad you found a way around the Just out of what the issue Kilian", "Dear Many I have logged on Phil Original Message June PM account Hi I created an account for try logging in Check out the wiki for more Please let us know if we can be of any more Alex On Philip Robinson Dear I am a research associate in the Kornberg group in structural biology and would like to request a user account on the Are you the correct guy to deal with Thanks in Phil Robinson", "I restarted the scheduler and Must be some bug in our version but been putting off any upgrades because likely we should do a full as all software on this cluster is getting Alex", "Hi It could well be that the compute nodes the jobs have a smaller set of packages tends to be graphical so maybe installed on the login node for but not on the compute Try a to get an Interactive shell on a compute Alex", "Hi mixtape in pypi it looks If it changes really fast maybe its better to install in your or is there a particular version I should", "using files to share data between MPI ranks on a single and when persisted on the lustre much slower than simply copying the data between the On getting good performance", "Part of the scheduler was down It is now running Thanks for the Will", "Hi I thought I sent this out my It was stuck in draft in this I deleted all your stuck I also rebooting those Will", "I think those jobs are terminated so it should get Kilian", "No glad you found the because I really find anything wrong with the Kilian", "Hi restarted the MDS Can you please take a look now and see if the login node responds also stopped your Could you please try to submit less jobs at a to see if it makes a Like submit one or and see how long they take to Then launch and Thanks Kilian", "Hi I created you account on You can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "Hi I created your account on You can SSH to with your SUNetID Check out the wiki for more feel free to Alex", "that seems to have fixed the problem my jobs are running without On Mar at Alex Chekholko Hi I rebooted those four nodes and I see anything wrong with works Try Or else let us know how to reproduce your Alex On Alex Chekholko Hi take a look I see all four nodes with GPU are reboot them and see if I see anything Alex On Jeffrey Weber Hi Do you know if anything has changed in the GPU configuration on in recent been successfully running OpenCL jobs for but I now receive a which seems to indicate that the cluster now has no OpenCL capable", "Hi There indeed seems to be a problem with some of the We took them offline and rebooted and now the pending jobs have started to flow investigating the source of the Sorry for the Kilian", "Hi I ran pbsnodes take a Alex", "Vijay Sent from my Sorry for the brevity or unusual", "Hi We have a wiki but it has very little running regular Please let us know if you have any happy to answer by We also have weekly office Alex", "Hi I created your account on You can SSH with your SUNetID credentials to Please see the wiki for more Alex", "Hi I see a blas installed on the login rpm blas I also installed that blas RPM on the compute Please let us know if we can be of any more Alex", "Thanks Yeah i was looking for a file in but good to know one in the Thanks Emma Emma Chory Chemical Engineering Candidate Crabtree Research Laboratory Stanford University", "Hi The useful queues on are called and Are you explicitly specifying as a queue Try just leaving that parameter your job will get routed looking at and Please let us know if we can be of any more Alex", "I noticed that and spent a few mins leaving it down and looking for but in the just restarted look more carefully through the Alex", "Your mail to with the subject queue Is being held until the list moderator can review it for The reason it is being Post by to a list Either the message will get posted to the or you will receive notification of the If you would like to cancel this please visit the following", "Hi So back in November you had prepared a list of things to on But I requested that backups be done before any If those things been revisit that list and add the scheduler upgrade to it as estimate the total downtime required and talk about when this could be Thanks Ruth"]}], "id": "el22918139732724253696", "width": 1080.0, "axes": [{"ydomain": [-0.6000000000000001, 0.8], "id": "el22918139732688785592", "zoomable": true, "texts": [{"zorder": 3, "text": "BioX3 Ticket Groupings", "id": "el22918139732732122616", "rotation": -0.0, "v_baseline": "auto", "alpha": 1, "h_anchor": "middle", "coordinates": "axes", "fontsize": 20.0, "color": "#000000", "position": [0.49999999999999994, 1.0059737156511348]}], "sharey": [], "yscale": "linear", "axes": [{"scale": "linear", "fontsize": 10.0, "tickformat": null, "tickvalues": null, "position": "bottom", "grid": {"gridOn": false}, "nticks": 9, "visible": true}, {"scale": "linear", "fontsize": 10.0, "tickformat": null, "tickvalues": null, "position": "left", "grid": {"gridOn": false}, "nticks": 10, "visible": true}], "sharex": [], "lines": [], "xdomain": [-0.4, 1.0], "markers": [], "collections": [{"edgewidths": [1.0], "zorder": 1, "pathcoordinates": "display", "id": "el22918139732732171992", "facecolors": ["#0FA2EF", "#7F00FF", "#2ADCDC", "#7F00FF", "#FF562B", "#FF562B", "#FF562B", "#0FA2EF", "#0FA2EF", "#FF0000", "#62FAC3", "#FF0000", "#FF562B", "#62FAC3", "#9CFAA3", "#FF562B", "#9CFAA3", "#9CFAA3", "#7F00FF", "#62FAC3", "#62FAC3", "#62FAC3", "#FFA256", "#0FA2EF", "#62FAC3", "#62FAC3", "#FF562B", "#FF562B", "#0FA2EF", "#2ADCDC", "#FFA256", "#2ADCDC", "#2ADCDC", "#62FAC3", "#62FAC3", "#62FAC3", "#0FA2EF", "#0FA2EF", "#7F00FF", "#9CFAA3", "#FF0000", "#2ADCDC", "#9CFAA3", "#FF562B", "#FF562B", "#0FA2EF", "#2ADCDC", "#7F00FF", "#FF0000", "#4756FB", "#FF562B", "#62FAC3", "#FF562B", "#0FA2EF", "#FF562B", "#FFA256", "#2ADCDC", "#FF562B", "#2ADCDC", "#62FAC3", "#FF0000", "#FF562B", "#D4DC7F", "#7F00FF", "#0FA2EF", "#FF0000", "#2ADCDC", "#2ADCDC", "#FF562B", "#7F00FF", "#9CFAA3", "#FFA256", "#7F00FF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#7F00FF", "#9CFAA3", "#62FAC3", "#FFA256", "#0FA2EF", "#FFA256", "#0FA2EF", "#FFA256", "#7F00FF", "#4756FB", "#FFA256", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#7F00FF", "#2ADCDC", "#62FAC3", "#4756FB", "#D4DC7F", "#4756FB", "#D4DC7F", "#9CFAA3", "#9CFAA3", "#7F00FF", "#FFA256", "#7F00FF", "#4756FB", "#4756FB", "#FF562B", "#62FAC3", "#D4DC7F", "#D4DC7F", "#0FA2EF", "#4756FB", "#FFA256", "#0FA2EF", "#FF0000", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#2ADCDC", "#FF562B", "#FFA256", "#FF562B", "#0FA2EF", "#2ADCDC", "#0FA2EF", "#FF0000", "#0FA2EF", "#0FA2EF", "#D4DC7F", "#0FA2EF", "#D4DC7F", "#D4DC7F", "#0FA2EF", "#62FAC3", "#62FAC3", "#7F00FF", "#0FA2EF", "#4756FB", "#FFA256", "#FFA256", "#FF562B", "#FFA256", "#2ADCDC", "#9CFAA3", "#FF0000", "#0FA2EF", "#0FA2EF", "#D4DC7F", "#D4DC7F", "#FFA256", "#FF0000", "#FFA256", "#2ADCDC", "#FF562B", "#D4DC7F", "#FF562B", "#62FAC3", "#2ADCDC", "#2ADCDC", "#7F00FF", "#2ADCDC"], "pathtransforms": [[4.47213595499958, 0.0, 0.0, 4.47213595499958, 0.0, 0.0]], "offsets": "data01", "xindex": 0, "alphas": [null], "edgecolors": ["#000000"], "yindex": 1, "offsetcoordinates": "data", "paths": [[[[0.0, -0.5], [0.13260155, -0.5], [0.25978993539242673, -0.44731684579412084], [0.3535533905932738, -0.3535533905932738], [0.44731684579412084, -0.25978993539242673], [0.5, -0.13260155], [0.5, 0.0], [0.5, 0.13260155], [0.44731684579412084, 0.25978993539242673], [0.3535533905932738, 0.3535533905932738], [0.25978993539242673, 0.44731684579412084], [0.13260155, 0.5], [0.0, 0.5], [-0.13260155, 0.5], [-0.25978993539242673, 0.44731684579412084], [-0.3535533905932738, 0.3535533905932738], [-0.44731684579412084, 0.25978993539242673], [-0.5, 0.13260155], [-0.5, 0.0], [-0.5, -0.13260155], [-0.44731684579412084, -0.25978993539242673], [-0.3535533905932738, -0.3535533905932738], [-0.25978993539242673, -0.44731684579412084], [-0.13260155, -0.5], [0.0, -0.5]], ["M", "C", "C", "C", "C", "C", "C", "C", "C", "Z"]]]}], "axesbg": "#FFFFFF", "ylim": [-0.6000000000000001, 0.8], "images": [], "bbox": [0.125, 0.125, 0.775, 0.775], "xscale": "linear", "xlim": [-0.4, 1.0], "paths": [], "axesbgalpha": null}]});
   }(mpld3);
}else if(typeof define === "function" && define.amd){
   // require.js is available: use it to load d3/mpld3
   require.config({paths: {d3: "https://mpld3.github.io/js/d3.v3.min"}});
   require(["d3"], function(d3){
      window.d3 = d3;
      mpld3_load_lib("https://mpld3.github.io/js/mpld3.v0.3.js", function(){
         
         mpld3.draw_figure("fig_el229181397327242536968160816196", {"data": {"data01": [[-0.10727242110819896, 0.056034466145307514], [-0.07767835522244931, -0.09371481278955099], [-0.0978237344576451, -0.08610370839997071], [-0.08691738313930335, -0.1612744533027579], [0.06861634964219782, -0.3327102476236188], [0.020462534824250842, -0.4052525062545243], [-0.04734683620069103, -0.2562199599830677], [-0.10182530593700469, 0.24268587970419536], [-0.07454360655456688, 0.10902708164934788], [-0.10138776781660104, 0.0012276187378888383], [-0.14397282706377795, 0.024980503818468617], [-0.06444760248637746, -0.02862344281074209], [-0.08433577114722553, 0.004471942212242875], [-0.1309294266637809, 0.023154881178064607], [-0.07568325588702912, 0.011378336917657758], [-0.02835991476525087, -0.08070278843722838], [-0.09874485256048857, -0.01122241255566899], [-0.09874485256048864, -0.011222412555669017], [-0.08812683544786963, -0.006108476423168935], [-0.17316814130533137, 0.1307711669369488], [-0.17247767029974898, 0.12238526531420814], [-0.13974407350726717, 0.08141205644887091], [-0.14989424790272515, 0.2532806138356442], [-0.07908288903702676, 0.2037002494758532], [-0.12278427807302474, 0.014655055991681992], [-0.119096562485101, 0.01248403253981233], [0.020326304544425165, -0.28479139768262945], [0.00579456757619414, -0.12107380365748166], [-0.08231125355502475, 0.02966881097084069], [-0.05087578967534923, -0.09164913657227229], [0.050378143880776466, -0.17921831634466712], [-0.0929396796138604, -0.04652841400054207], [-0.05662725301152238, -0.10257948753039688], [-0.1309294266637809, 0.023154881178064565], [-0.1208914948530424, 0.01684611185017089], [-0.0911848498413192, -0.005111871395159533], [-0.1503684346427546, 0.4188142074888131], [-0.07540571148337409, 0.054827013588195826], [-0.035604387651408526, -0.2772416871366358], [-0.06647566199977781, -0.02741099491654421], [-0.12277757820114901, -0.0830164906591825], [-0.055756589590237896, -0.22160829245736074], [-0.10165953721554193, -0.020218186525082907], [0.0281998668847653, -0.25403166603415517], [0.04476629712105019, -0.4193913731552902], [-0.0958199240859659, 0.07875595154982604], [-0.042345947578282, -0.18572854695236743], [0.004664622448618803, -0.2514536840310804], [-0.0680439606634897, -0.13867882084924563], [0.4259417842645283, -0.21758005709446757], [-0.01697605460961052, -0.1765096131686985], [-0.1422209522943006, 0.20254861140087005], [0.012333595206254315, -0.2746531332753382], [-0.08324637829561694, 0.09569131669632597], [-0.007708497996513715, -0.2794299609830357], [-0.02360488800798698, -0.22298066223219382], [-0.09546380497381031, -0.08866860018078537], [0.029896123788976367, -0.10081490139792643], [-0.09493187650362522, -0.0078043508936891], [-0.21076886830808403, 0.45567277273550155], [-0.12303681517110253, -0.05108015225825407], [0.07469717593723543, -0.11228152133563582], [0.5947508332026333, 0.21588077071863734], [-0.10870580744896648, -0.1513503405668154], [-0.08356047354412158, 0.11284097989096754], [-0.09657373586303422, -0.21589185219208], [-0.0506151934706682, -0.339445817645953], [-0.07175507801076082, -0.06651727509431667], [0.008943821895630354, -0.08497654183786098], [-0.1087058074489665, -0.1513503405668154], [-0.09545061623281982, -0.06628707727125276], [-0.12516379982454034, -0.034175893409573485], [-0.11523684887518605, -0.008701037522590488], [-0.17536595654468357, 0.5360825663045121], [-0.17536595654468365, 0.5360825663045121], [-0.16261343440647455, 0.4439700188855954], [-0.09210844256778558, 0.049248319267324564], [-0.09543866555157351, 0.0499176760007965], [-0.08891958319079712, 0.04557302979206468], [-0.03816952336861682, -0.1119368414468306], [-0.12214959572013558, -0.010598505212340438], [-0.04775269252569938, -0.11520554186999407], [-0.0835852719170874, 0.5263295059978612], [-0.039216984367689854, -0.11678860656719997], [-0.10525170492027608, 0.1756266001913818], [-0.07282658494847785, -0.22741101813509831], [-0.1251185356778328, -0.1556817158046111], [0.2437863442768604, 0.11619932297175162], [-0.09187093612880828, 0.02932137339818053], [-0.10443960458567873, 0.06216005502350786], [-0.16822232801012665, 0.3808437469933286], [-0.08005073586492858, 0.0663230562842798], [-0.11330299783230699, -0.15428356869833562], [-0.05705262551759115, -0.30509362877735374], [-0.08618886102424125, 0.13305188088888906], [0.6355186445607468, 0.005168544107673091], [0.7743535206282145, -0.0800316461984685], [0.4173927827199395, -0.04236383955396936], [0.71506549507598, -0.10431073730256865], [-0.06939220758403612, -0.12224266337564357], [-0.08432378030687969, -0.06648903478004169], [-0.11330299783230693, -0.15428356869833576], [-0.08630323401987747, -0.11699305539250862], [-0.02179585265157594, -0.2899871415663814], [0.32632199690626457, 0.36893761425915694], [0.4538765865809893, 0.2807583750722457], [-0.0964844829409978, 0.029921792832450073], [-0.1399574288465819, 0.13810596944588777], [0.6835381107205909, -0.07057017052292087], [0.7302469646278138, 0.0691210389768199], [-0.09060468878350333, 0.10352275179875504], [0.6895934638092436, -0.16441377097970084], [-0.03548859719155889, -0.09221175973127024], [-0.105251704920276, 0.17562660019138177], [-0.09208321913152809, -0.17836293923188254], [-0.20139647121090978, 0.6766069510948846], [-0.1479508057806757, 0.34899243162967397], [-0.17050849074821467, 0.45849460790470614], [-0.08358527191708742, 0.5263295059978613], [-0.10617374190240998, -0.048089298811109], [-0.02261875797695372, -0.05688718102191002], [-0.12926118666513411, -0.07571138445097629], [-0.0008171648004735801, -0.06788772733711064], [-0.08957200309419978, 0.08525395287656129], [-0.04650483476473082, -0.05390457770629112], [-0.07701351549043492, 0.14194523058608333], [-0.11861161143762271, -0.11589398143117365], [-0.08794675374543778, 0.07002078319517595], [-0.09220756553219878, 0.050602261525988644], [0.7045522044021921, 0.2784168052583952], [-0.10656978516320055, 0.052903132998516754], [0.7045522044021922, 0.27841680525839524], [0.7045522044021922, 0.27841680525839524], [-0.09101237185799595, 0.09209052079244932], [-0.12043995800400602, 0.01422682742676336], [0.01712307057999428, 0.10232630416452013], [-0.09414642750543399, -0.021918995452943613], [-0.08278090438070876, 0.0773037382073881], [0.30616718854934655, 0.0012406372013222377], [-0.0659243732370409, -0.09492799813832493], [-0.07839960833753436, -0.19739056645473776], [-0.08904678916024408, -0.050185264944005416], [-0.08243620588887964, -0.015559858724626379], [-0.17034628364311002, 0.1904928612444531], [-0.07868726677739138, -0.03407793941013253], [-0.11635513166282702, 0.12262847906023745], [-0.07688540575835495, 0.1158132654047259], [-0.1342422274628025, 0.06087211623705313], [0.7735441987928864, 0.270335465601552], [0.8069829116565443, 0.11716714061509095], [-0.025583947144065464, -0.3509410091161083], [-0.10718185167941129, -0.06949656513505865], [0.007700126164142015, -0.1583448734590568], [-0.09546380497381031, -0.08866860018078536], [0.21175637076687379, -0.29612256672049014], [0.6988893557780519, 0.05582709769867708], [0.013766150339171137, -0.24578335284767344], [-0.14587866623254517, 0.1512248308982449], [-0.00724509912790304, -0.259077444693641], [-0.053440350818153924, -0.12146259540453364], [-0.07896939382744605, -0.06267148582937929], [-0.11571708498923118, 0.06145799897899285]]}, "height": 1080.0, "plugins": [{"type": "reset"}, {"type": "zoom", "enabled": false, "button": true}, {"type": "boxzoom", "enabled": false, "button": true}, {"hoffset": 0, "id": "el22918139732732171992", "location": "mouse", "type": "tooltip", "voffset": 10, "labels": ["Hi for the take a look as we bring nodes back online after the Kilian", "did find one node which had unmounted the and I disabled that I would have expected some kind of not message or something", "Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine On Jun at Alex Chekholko A number of compute nodes on are down with hardware so these jobs have I will purge them from the output in a few ACTIVE JOBNAME USERNAME STATE PROC REMAINING STARTTIME rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May Running Wed May Running Wed May Running Wed May rhiju Running Wed May Running Wed Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun Running Fri Jun Alex Chekholko", "forced the deletion of the problematic I rebooted a couple of the nodes including and they are down with some hardware", "please let us know if you need anything", "Hi rebooted that node and another Please let us know if you have any other", "Hi Thank you for your I relaunched some I still see my jobs from before running and all the new in the I know if there are no more nodes available should get instead of but at least the queue is let you know if I experience anything weird going Johan", "Thank you this is much Kilian", "Hi The accounts have been removed from both and and the associated data Kilian", "Hi the filesystem is full on despite the numerous warnings sent in the As a jobs will fail and application will generate errors until the situation is rules are in place to make sure usage is equally shared between groups and and prevent situation where a single user could monopolize the whole Kilian", "that was Things are looking Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Mark you have emailed me times about Can you I said I am not having issues", "the problem is that the most recent GCC version that the distribution provides is There is also a version you can try in if it work I would suggest trying to compile a newer GCC in your home Kilian", "I will not be monitoring consistently through the Please expect delays in response until Rhiju Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Hi Thanks for your patience while resolving The filesystem is back in finishing troubleshooting a few compute Filesystem access should be working normally from the login Please let us know if you notice any Kilian", "Hi The filesystem on experienced some We believe they are resolved so you should be able to log in without any Please let us know if you still experience any Kilian", "Hi We think the issue was that the filesystem was mostly full in terms of inodes such as files or As a any process creating a lot of small such as a was generating a huge load on the metadata which was in turn struggling to allocate new objects in a very constrained That load very likely was the reason why the filesystem seemed really slow at Some cleanup had been done on the filesystem still need to be so if you have files that you really need on please hesitate to remove and we think that the issue should be solved for Kilian", "Hi We think the issue was that the filesystem was mostly full in terms of inodes such as files or As a any process creating a lot of small such as a was generating a huge load on the metadata which was in turn struggling to allocate new objects in a very constrained That load very likely was the reason why the filesystem seemed really slow at Some cleanup had been done on the filesystem still need to be so if you have files that you really need on please hesitate to remove and we think that the issue should be solved for Kilian", "Thank you very much for your Kalli", "Thanks very Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Things are getting progressively better we were quite anxious over the weekend many thanks for your Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Hi thanks for the I have been doing calculations and everything has been I guess I should not have been trying to do calculations over Paul Ruijgrok Postdoctoral Scholar in Bryant Molecular Motors Lab email lab phone Web Mailing and visiting Stanford University Department of Bioengineering VIA ORTEGA BioEngineering CA", "I can kill them thanks Zheng", "Hi this is more information about is available at Kilian", "connected thank you so Paul Paul Ruijgrok Postdoctoral Scholar in Bryant Molecular Motors Lab email lab phone Web Mailing and visiting Stanford University Department of Bioengineering VIA ORTEGA BioEngineering CA", "Paul Ruijgrok Postdoctoral Scholar in Bryant Molecular Motors Lab email lab phone Web Mailing and visiting Stanford University Department of Bioengineering VIA ORTEGA BioEngineering CA", "We have an easy way to roll that software out on so just do it on the login node Please let us know if you have any Alex", "Hi find your compiled version in Please give it a try and let us know how it Kilian", "you should probably remove About the temporarily you had thousands of processes running on the login probably a fork loop gone I killed You should be able to connect Kilian", "Hi how come you set But you request only cores from the So this job runs iterations of an osprey Or it launcher simultaneous instances of Alex", "Sorry for the feel free to drop those I rebooted a couple of compute nodes that ended up in a weird state and also contacted the Alex", "seeing this same problem again on Would it be possible to try restarting the scheduler Kalli", "Hi Sorry for the I changed our script to restart the scheduler twice a day instead of once a see what happens It is set to automatically restart at and at Alex", "I am out of town with family and will not be monitoring consistently through the end of Please expect delays in response until Rhiju Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Thank Sabina Sood Stem Cell Biology Candidate Gerald Crabtree Lab Stanford Medical School", "Hi Thank I am able to log in through sherlock and then which works well for Han Han Institute of Candidate in Biological", "HI Thanks for much I guess go the hard reset Kilian", "Hi Your group is actually pretty good on that your aggregated usage is about which is far less than the biggest individual And by the there is not much alternatives in terms of storage as on and are actually the same Kilian", "I disabled and rebooted that sorry for the Alex", "I appreciate your help resolving this The program runs Matias", "Hi On as a member of an owner you would be able to submit jobs to the partition and effectively get access to every single node on Sherlock as of which is way more than a all jobs submitted to the owners partition are subject to That if the owners of the nodes your jobs are running on needs their your jobs will be killed and Some applications can resume from where they left some and need some cleanup to be able to but besides some this could be a great way to get access to massive amounts of computing Kilian", "Hi Sorry for the I see there was a problem with the scheduler on I restarted it and job reporting is OK I see a job for you either running or so maybe your job already Please let us know if you have any other Alex", "Thank Amanda Miguel Sent with Airmail", "We resolved the issue with the filesystem on Please let us know if you encounter any other Alex", "I rebooted that Please let us know if you see any other", "Sorry about this and for the I am on it and should be able to delete at least some of the stuff on here Steven On Apr at Kilian Cavalotti Hi currently the top user in terms of storage space used in the with more than If you could please do some cleanup and remove files you need that would be Kilian", "Hi I restarted the Please try Sorry for the Alex", "Hi I went ahead and disabled that node and will reboot it and take a closer Please let us know if you have any other Alex", "Hi I see there are a lot of jobs on the but I see any jobs from Are you still having any Alex", "Hi I created your account on You can find more info Please let us know if we can be of any more Alex", "Hi Jupyter is a so I think most people install and update it I can recommend the Anaconda python distribution which installs into your homedir and updates And require any sysadmin So I recommend you use Please let us know if we can be of any more Alex", "thanks very much it does appear to be working Joe", "Hi Not sure about your login but it looks like been able to log in since through another If you even ping something is wacky about either your local DNS or your local network If you still have connectivity problems let me know the host from which connecting and we can figure it Please let us know if we can be of any more Alex", "I just killed the it send emails Cheers Kilian", "Hi It looks like is not available for our older version of We currently have any plans to upgrade on Sorry for the Please let us know if we can be of any more Alex", "Hi take a That cluster is overdue for so some nodes are misbehaving Alex", "I Vijay Sent from my Sorry for the brevity or unusual", "Let me know if you still encounter Kilian", "Hi It would indeed be better to submit a job to do You can launch an interactive job in a session if you want to be able to interact with your Something qsub waiting for job to start job ready This you can detach your screen session and reconnect to it later with on the login Kilian", "I Thanks very much for the Wen", "Hi Do you have a way to break up your jobs into smaller chunks so that they finish in under I think it was the cluster PIs who wanted to bump down the time I see we sent a note to on June Dear Due to the recent trend of increasing wait times in scheduler modified some in order to lower the barrier of entry for users who constantly submit As of the following modifications come into the maximum number of CPUs any given user can use at once is the default walltime limit for jobs is and the maximum that can be requested is a new QOS is introduced that could allow to exceed the CPUs limit when the cluster is This QOS makes jobs meaning that they can be killed and requeued if resources are requested from other To use that one can use the submission as The immediate effect will be that more resources should be kept available for monitor the state of the queue for the next few days to see if the situation improves and if adjustments are Kilian", "Let us know if we can be of any more Kilian", "Hi Your account on has been You can SSH with your SUNetID credentials to Check out the wiki page for more Kilian", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy DNS On November the legacy DNS service will be Please update the DNS configuration on your node or nodes to use the anycast DNS service as described Here is a list of your nodes that queried the legacy DNS service on Monday", "maybe the previous email stream ending and the last emails being Kilian", "Hi Sorry about a couple of nodes crashed and I forgot to disable them before rebooting and your jobs got sent to them immediately as they came but before they mounted the shared So the jobs errored Please resubmit and Alex", "Sorry about a few nodes and we rebooted them go do that Alex", "Hi the limit on the maximum number of CPUs per user was applied to all including the background That should be fixed Note that still a limit on the number of CPUs usable with the background so we can still keep resources available for but much higher than in the default So I believe the problem is fixed And I think the job defaulting to the NORMAL QOS Please try and let me know if you still see any Kilian", "No Let me know if you notice anything unexpected under the new Kilian", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy DNS On November the legacy DNS service will be Please update the DNS configuration on your node or nodes to use the anycast DNS service as described Here is a list of your nodes that queried the legacy DNS service on Monday", "Note that disk the whole filesystem goes I suggest we do this by CPU usage not file system usage since there will be no CPU usage a Vijay Sent from my Sorry for the brevity or unusual", "Hi was efficient or and I have the It ran with and one process per did not produce any out put after more than I killed It ran without and one process per node So far I understand I should run with less processes per even if this is not and use Thank Yana Yana Gofman Postdoctoral Fellow Michael Levitt Lab Department of Structural Biology Stanford University School of Medicine James Clark Center Campus Room CA", "Hi This is indeed what I eventually did but I also had to do Not sure but it did not work thought that if I ask each process uses of it should be and fits the machine but somehow it did not work this thank you very Yana Yana Gofman Postdoctoral Fellow Michael Levitt Lab Department of Structural Biology Stanford University School of Medicine James Clark Center Campus Room CA", "Hi No Thanks for your effort and for your this is much Kilian", "Hi Thanks for your effort and for your this is much Kilian", "Hi Thanks a lot for your effort and your this is much Kilian", "Hi a few days is perfectly We just want to make sure that all the and obsolete files are cleaned up so room can be made for more useful Kilian", "Hi for getting back to and for your cooperation in that can keep as much as you We just want to make sure that all the and obsolete files are cleaned up so room can be made for more useful Kilian", "Hi Those failures were caused by the local disk being full on some of the compute I did some cleanup so it should be better And I believe the errors you had on were caused by the same Kilian", "I ended up just killing old processes from people not logged in that are more than a week Alex", "Just running basic commands seemed abnormally but now working much Erik Erik Postdoctoral Scholar Gerald Crabtree Lab Stanford University", "Hi I think usually that means that the kernel killed that usually because it used up all the system Do you know how much memory your program Perhaps the memory usage varies with input data or some Alex", "Should be back in business Kilian", "Hi I power cycled look for them to come back up in a couple of Alex", "Hi I restarted the it should come back Kilian", "Some of the nodes I rebooted them and your old jobs Consider requesting more memory for your in case they ran out of Alex", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still attempting to use the legacy NTP service even though been turned Please consider updating the NTP configuration on your nodes to use the current NTP service as described Make sure to restart the NTP process reboot the so it uses the new Here is a list of your nodes that need to be updated", "Hi I created your account on You can connect the the login node with Please see for more Kilian", "I found the following on the Out of Kill process process UID So you could try to reduce the total number of processes as well as the number of processes per Kilian", "Hi not completely but quite Definitely very rebooted it should come back online Kilian", "Hi Thanks for the The Maui scheduler That should be better Kilian", "Hi not sure what you mean by Your state is which means eligible to run and will start as soon as enough resources are Kilian", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy NTP service that was replaced years On May the systems providing the legacy NTP service will no longer respond to NTP Please update the NTP configuration on your nodes to use the current NTP service as described Here is a list of your nodes that need to be", "Hi Looks like you submitted a bunch of jobs with small resource they all ended up scheduled to the same physical and that node crashed after maybe running out of I went ahead and rebooted that Maybe adjust your resource requests per job up a Please let us know if we can be of any more You can use the command to see your Alex", "Hi Thanks for the Alex was able to provide what we", "I created the vineetk account on Check out the wiki link for more Alex", "Hi I created your account on You can SSH with your SUNetID Check out the wiki link in the motd for more Please let us know if we can be of any more Alex", "I added the account for enf on More info at the wiki and in the Alex", "Hi I created your account on You can SSH to with your SUNetID a link to the wiki in the Please let us know if we can be of any more Alex", "I removed many TBs Hopefully this is enough Matt Original Message Computing March AM Filesystem usage on Hi currently using about on which makes you the largest consumer of storage resources on that Since the filesystem starts to fill we would appreciate if you could do some cleanup in your old remove the ones you need and maybe transfer out the ones you want to keep on the longer Please let me know if you have any Research Computing Support", "Thanks for the clean some stuff up over the On March Research Computing Support Hi currently using on which makes you the largest consumer of storage resources on that Since the filesystem starts to fill we would appreciate if you could do some cleanup in your old remove the ones you need and maybe transfer out the ones you want to keep on the longer Please let me know if you have any Research Computing Support Sent from my", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy NTP service that was replaced years On May the systems providing the legacy NTP service will no longer respond to NTP Please update the NTP configuration on your nodes to use the current NTP service as described Here is a list of your nodes that need to be", "Thanks for the Will keep it in mind in the Steven On Feb at Alex Chekholko Looks like a lot of these jobs are so likely they are running slower than you sryckbos Ss sryckbos S sryckbos Dl worker sryckbos Dl worker sryckbos Rl worker sryckbos Dl worker sryckbos Dl worker sryckbos Dl worker On Alex Chekholko I was looking around at some compute and I see your osprey jobs sometimes run out of memory and get Out of Kill process score or sacrifice child Killed process UID You may want to request more memory for those Alex Chekholko", "Hi I took a look at that jobid and it looks like there is some minor problem with one compute disabled that compute node and will take a closer Please let us know if you see any other Alex", "Hi Your account on has been Kilian", "Hi I created your account on Kilian", "Hi GCC is installed on node You can use it scl enable bash posixgcc version Hat Kilian", "Thanks working great Nir Nir of Biological Chemistry The Silberman Institute of Life Sciences The Hebrew University of Jerusalem Lab", "Hi I created your account on You can SSH with your SUNetID credentials to Check out the wiki page for more Please let us know if you need anything Alex", "Hi I created your account on You can SSH to with your SUNetID so your username is Check out the wiki for more Alex", "Hi Matlab is not installed on You can use it on Farmshare see for Kilian", "I created your account on Check out the wiki for more Please let us know if you have any Alex", "Accounts are always mapped to On we use Unix groups to group people by their Alex", "Hi I restarted those they should come back Kilian", "Hi I see you have two jobs listed and each is on a crashed nodes and go reboot those and you should see those jobs Alex", "Hi Thanks for letting me Kilian", "Hi Reboot is thanks for reporting Kilian", "Hi Thanks for the the reboot is Kilian", "No On we have and Kilian", "Hi I took the example of job It runs on as well as job ids to all of which are Those processes seem indeed all be stuck on something as they use any CPU time at all on the Looking in more it looks like stuck on some sort of the backtrace for one of gstack in from in from in from in fork from in from in from handler in from in malloc from in in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in in in in in in in in main From that trace it looks like the process received a signal forked and then is now waiting on a Does that sound familiar to you regarding the Do you now what kind of signal the application may have Kilian", "Hi This fixed our are not using python scripts in the jobs but they may otherwise make use of the abrt socket check the source Rosetta And abrt adds a new exception handler that overrides the default See let the rest of my lab know that fixed the And as per your other send a note to the mailing Kilian", "Hi Thanks for the detailed Looking at your idle processes on that specific it looks like they were stuck on connecting to the abrt abrt is a to help users to detect defects in applications and to create a bug report with all informations needed by maintainer to fix I think you were using it on purpose me if but since it provides python bindings which may be active by likely that the python scripts in your jobs were using there seems to be a bug with so I removed it from the compute And it looks like it even unblocked your previously idle Let me know if it really fixes your Kilian On Rhiju Das Hi Thanks for helping set up the two new users from my lab so We had one more question seen this in the but now its getting a little I will often kick off and see them as running but then they never actually use any CPU time or do After the wall time is they are This has not been mission critical for the last few but is about to be a big pasting below an example of such a zombie job running right now On the same node there are four other jobs from me that are running fine which I can see via but this and its sisters are not going No one else seems to be running on that I tried to reduce the declared memory to the default of but that Any advice would be We want to be the ones tying up the queue with zombie Rhiju qstat Job R queue SP server Checkpoint u ctime Fri Sep n n n n mtime Fri Sep Priority qtime Fri Sep Rerunable True etime Fri Sep Fri Sep False", "No Let me know if it changes things for Kilian", "Hi Nice to Regarding I think it can be used on without a But installed and licensed on Farmshare and Kilian", "Hi The memory usage of a job at some point in time is not always representative of its peak So maybe on the nodes the jobs were not using all the memory they requested at that specific but perhaps they will need it gonna check with the see if intended an what his real usage Kilian", "Hi The NVIDIA kernel module was not loaded correctly on that It should be fixed Kilian", "Hi I restarted the and it looks like the runaway jobs have Regarding the high number of jobs as Alex explained due to the nature of the jobs currently If you run see that most nodes that have cores available have very little memory in any case not enough to run the jobs that are There are a few nodes for which the scheduler state does not match their real load probably because of runaway gonna take care of but it change much regarding the pending Kilian", "Hi The node crashed and failed to remount the directory at fixed Kilian", "Hi has been rebooted and should be back online And I deleted your Kilian", "Hi account has been You can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "Hi was indeed overloaded with user processes and partially rebooted the it should come back online Kilian", "Hi account has been You can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "Hi Your account has been can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "No And sorry we have a more recent Kilian", "Erik Miller Candidate Department of Genetics Gerald Crabtree Lab Stanford University", "Thanks you should be able to log in with your normal Stanford username and with ssh Here is the wiki for During our next go over how to submit jobs on this awesome Best Alexandre Alexandre Colavin Biophysics PhD Candidate Huang Lab Stanford University", "Hi We do not handle the billing for use of that is managed through the I would recommend you contact Levitt and To my only the PIs who are entitled to use the I do not see Weis in that Pande Levitt Altman Huang Das Bryant Crabtree Guibas Covert Darve Martinez Kornberg When did you get an Were you working with another Ruth", "Hi Glad you found a way around the Just out of what the issue Kilian", "Dear Many I have logged on Phil Original Message June PM account Hi I created an account for try logging in Check out the wiki for more Please let us know if we can be of any more Alex On Philip Robinson Dear I am a research associate in the Kornberg group in structural biology and would like to request a user account on the Are you the correct guy to deal with Thanks in Phil Robinson", "I restarted the scheduler and Must be some bug in our version but been putting off any upgrades because likely we should do a full as all software on this cluster is getting Alex", "Hi It could well be that the compute nodes the jobs have a smaller set of packages tends to be graphical so maybe installed on the login node for but not on the compute Try a to get an Interactive shell on a compute Alex", "Hi mixtape in pypi it looks If it changes really fast maybe its better to install in your or is there a particular version I should", "using files to share data between MPI ranks on a single and when persisted on the lustre much slower than simply copying the data between the On getting good performance", "Part of the scheduler was down It is now running Thanks for the Will", "Hi I thought I sent this out my It was stuck in draft in this I deleted all your stuck I also rebooting those Will", "I think those jobs are terminated so it should get Kilian", "No glad you found the because I really find anything wrong with the Kilian", "Hi restarted the MDS Can you please take a look now and see if the login node responds also stopped your Could you please try to submit less jobs at a to see if it makes a Like submit one or and see how long they take to Then launch and Thanks Kilian", "Hi I created you account on You can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "Hi I created your account on You can SSH to with your SUNetID Check out the wiki for more feel free to Alex", "that seems to have fixed the problem my jobs are running without On Mar at Alex Chekholko Hi I rebooted those four nodes and I see anything wrong with works Try Or else let us know how to reproduce your Alex On Alex Chekholko Hi take a look I see all four nodes with GPU are reboot them and see if I see anything Alex On Jeffrey Weber Hi Do you know if anything has changed in the GPU configuration on in recent been successfully running OpenCL jobs for but I now receive a which seems to indicate that the cluster now has no OpenCL capable", "Hi There indeed seems to be a problem with some of the We took them offline and rebooted and now the pending jobs have started to flow investigating the source of the Sorry for the Kilian", "Hi I ran pbsnodes take a Alex", "Vijay Sent from my Sorry for the brevity or unusual", "Hi We have a wiki but it has very little running regular Please let us know if you have any happy to answer by We also have weekly office Alex", "Hi I created your account on You can SSH with your SUNetID credentials to Please see the wiki for more Alex", "Hi I see a blas installed on the login rpm blas I also installed that blas RPM on the compute Please let us know if we can be of any more Alex", "Thanks Yeah i was looking for a file in but good to know one in the Thanks Emma Emma Chory Chemical Engineering Candidate Crabtree Research Laboratory Stanford University", "Hi The useful queues on are called and Are you explicitly specifying as a queue Try just leaving that parameter your job will get routed looking at and Please let us know if we can be of any more Alex", "I noticed that and spent a few mins leaving it down and looking for but in the just restarted look more carefully through the Alex", "Your mail to with the subject queue Is being held until the list moderator can review it for The reason it is being Post by to a list Either the message will get posted to the or you will receive notification of the If you would like to cancel this please visit the following", "Hi So back in November you had prepared a list of things to on But I requested that backups be done before any If those things been revisit that list and add the scheduler upgrade to it as estimate the total downtime required and talk about when this could be Thanks Ruth"]}], "id": "el22918139732724253696", "width": 1080.0, "axes": [{"ydomain": [-0.6000000000000001, 0.8], "id": "el22918139732688785592", "zoomable": true, "texts": [{"zorder": 3, "text": "BioX3 Ticket Groupings", "id": "el22918139732732122616", "rotation": -0.0, "v_baseline": "auto", "alpha": 1, "h_anchor": "middle", "coordinates": "axes", "fontsize": 20.0, "color": "#000000", "position": [0.49999999999999994, 1.0059737156511348]}], "sharey": [], "yscale": "linear", "axes": [{"scale": "linear", "fontsize": 10.0, "tickformat": null, "tickvalues": null, "position": "bottom", "grid": {"gridOn": false}, "nticks": 9, "visible": true}, {"scale": "linear", "fontsize": 10.0, "tickformat": null, "tickvalues": null, "position": "left", "grid": {"gridOn": false}, "nticks": 10, "visible": true}], "sharex": [], "lines": [], "xdomain": [-0.4, 1.0], "markers": [], "collections": [{"edgewidths": [1.0], "zorder": 1, "pathcoordinates": "display", "id": "el22918139732732171992", "facecolors": ["#0FA2EF", "#7F00FF", "#2ADCDC", "#7F00FF", "#FF562B", "#FF562B", "#FF562B", "#0FA2EF", "#0FA2EF", "#FF0000", "#62FAC3", "#FF0000", "#FF562B", "#62FAC3", "#9CFAA3", "#FF562B", "#9CFAA3", "#9CFAA3", "#7F00FF", "#62FAC3", "#62FAC3", "#62FAC3", "#FFA256", "#0FA2EF", "#62FAC3", "#62FAC3", "#FF562B", "#FF562B", "#0FA2EF", "#2ADCDC", "#FFA256", "#2ADCDC", "#2ADCDC", "#62FAC3", "#62FAC3", "#62FAC3", "#0FA2EF", "#0FA2EF", "#7F00FF", "#9CFAA3", "#FF0000", "#2ADCDC", "#9CFAA3", "#FF562B", "#FF562B", "#0FA2EF", "#2ADCDC", "#7F00FF", "#FF0000", "#4756FB", "#FF562B", "#62FAC3", "#FF562B", "#0FA2EF", "#FF562B", "#FFA256", "#2ADCDC", "#FF562B", "#2ADCDC", "#62FAC3", "#FF0000", "#FF562B", "#D4DC7F", "#7F00FF", "#0FA2EF", "#FF0000", "#2ADCDC", "#2ADCDC", "#FF562B", "#7F00FF", "#9CFAA3", "#FFA256", "#7F00FF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#7F00FF", "#9CFAA3", "#62FAC3", "#FFA256", "#0FA2EF", "#FFA256", "#0FA2EF", "#FFA256", "#7F00FF", "#4756FB", "#FFA256", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#7F00FF", "#2ADCDC", "#62FAC3", "#4756FB", "#D4DC7F", "#4756FB", "#D4DC7F", "#9CFAA3", "#9CFAA3", "#7F00FF", "#FFA256", "#7F00FF", "#4756FB", "#4756FB", "#FF562B", "#62FAC3", "#D4DC7F", "#D4DC7F", "#0FA2EF", "#4756FB", "#FFA256", "#0FA2EF", "#FF0000", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#2ADCDC", "#FF562B", "#FFA256", "#FF562B", "#0FA2EF", "#2ADCDC", "#0FA2EF", "#FF0000", "#0FA2EF", "#0FA2EF", "#D4DC7F", "#0FA2EF", "#D4DC7F", "#D4DC7F", "#0FA2EF", "#62FAC3", "#62FAC3", "#7F00FF", "#0FA2EF", "#4756FB", "#FFA256", "#FFA256", "#FF562B", "#FFA256", "#2ADCDC", "#9CFAA3", "#FF0000", "#0FA2EF", "#0FA2EF", "#D4DC7F", "#D4DC7F", "#FFA256", "#FF0000", "#FFA256", "#2ADCDC", "#FF562B", "#D4DC7F", "#FF562B", "#62FAC3", "#2ADCDC", "#2ADCDC", "#7F00FF", "#2ADCDC"], "pathtransforms": [[4.47213595499958, 0.0, 0.0, 4.47213595499958, 0.0, 0.0]], "offsets": "data01", "xindex": 0, "alphas": [null], "edgecolors": ["#000000"], "yindex": 1, "offsetcoordinates": "data", "paths": [[[[0.0, -0.5], [0.13260155, -0.5], [0.25978993539242673, -0.44731684579412084], [0.3535533905932738, -0.3535533905932738], [0.44731684579412084, -0.25978993539242673], [0.5, -0.13260155], [0.5, 0.0], [0.5, 0.13260155], [0.44731684579412084, 0.25978993539242673], [0.3535533905932738, 0.3535533905932738], [0.25978993539242673, 0.44731684579412084], [0.13260155, 0.5], [0.0, 0.5], [-0.13260155, 0.5], [-0.25978993539242673, 0.44731684579412084], [-0.3535533905932738, 0.3535533905932738], [-0.44731684579412084, 0.25978993539242673], [-0.5, 0.13260155], [-0.5, 0.0], [-0.5, -0.13260155], [-0.44731684579412084, -0.25978993539242673], [-0.3535533905932738, -0.3535533905932738], [-0.25978993539242673, -0.44731684579412084], [-0.13260155, -0.5], [0.0, -0.5]], ["M", "C", "C", "C", "C", "C", "C", "C", "C", "Z"]]]}], "axesbg": "#FFFFFF", "ylim": [-0.6000000000000001, 0.8], "images": [], "bbox": [0.125, 0.125, 0.775, 0.775], "xscale": "linear", "xlim": [-0.4, 1.0], "paths": [], "axesbgalpha": null}]});
      });
    });
}else{
    // require.js not available: dynamically load d3 & mpld3
    mpld3_load_lib("https://mpld3.github.io/js/d3.v3.min.js", function(){
         mpld3_load_lib("https://mpld3.github.io/js/mpld3.v0.3.js", function(){
                 
                 mpld3.draw_figure("fig_el229181397327242536968160816196", {"data": {"data01": [[-0.10727242110819896, 0.056034466145307514], [-0.07767835522244931, -0.09371481278955099], [-0.0978237344576451, -0.08610370839997071], [-0.08691738313930335, -0.1612744533027579], [0.06861634964219782, -0.3327102476236188], [0.020462534824250842, -0.4052525062545243], [-0.04734683620069103, -0.2562199599830677], [-0.10182530593700469, 0.24268587970419536], [-0.07454360655456688, 0.10902708164934788], [-0.10138776781660104, 0.0012276187378888383], [-0.14397282706377795, 0.024980503818468617], [-0.06444760248637746, -0.02862344281074209], [-0.08433577114722553, 0.004471942212242875], [-0.1309294266637809, 0.023154881178064607], [-0.07568325588702912, 0.011378336917657758], [-0.02835991476525087, -0.08070278843722838], [-0.09874485256048857, -0.01122241255566899], [-0.09874485256048864, -0.011222412555669017], [-0.08812683544786963, -0.006108476423168935], [-0.17316814130533137, 0.1307711669369488], [-0.17247767029974898, 0.12238526531420814], [-0.13974407350726717, 0.08141205644887091], [-0.14989424790272515, 0.2532806138356442], [-0.07908288903702676, 0.2037002494758532], [-0.12278427807302474, 0.014655055991681992], [-0.119096562485101, 0.01248403253981233], [0.020326304544425165, -0.28479139768262945], [0.00579456757619414, -0.12107380365748166], [-0.08231125355502475, 0.02966881097084069], [-0.05087578967534923, -0.09164913657227229], [0.050378143880776466, -0.17921831634466712], [-0.0929396796138604, -0.04652841400054207], [-0.05662725301152238, -0.10257948753039688], [-0.1309294266637809, 0.023154881178064565], [-0.1208914948530424, 0.01684611185017089], [-0.0911848498413192, -0.005111871395159533], [-0.1503684346427546, 0.4188142074888131], [-0.07540571148337409, 0.054827013588195826], [-0.035604387651408526, -0.2772416871366358], [-0.06647566199977781, -0.02741099491654421], [-0.12277757820114901, -0.0830164906591825], [-0.055756589590237896, -0.22160829245736074], [-0.10165953721554193, -0.020218186525082907], [0.0281998668847653, -0.25403166603415517], [0.04476629712105019, -0.4193913731552902], [-0.0958199240859659, 0.07875595154982604], [-0.042345947578282, -0.18572854695236743], [0.004664622448618803, -0.2514536840310804], [-0.0680439606634897, -0.13867882084924563], [0.4259417842645283, -0.21758005709446757], [-0.01697605460961052, -0.1765096131686985], [-0.1422209522943006, 0.20254861140087005], [0.012333595206254315, -0.2746531332753382], [-0.08324637829561694, 0.09569131669632597], [-0.007708497996513715, -0.2794299609830357], [-0.02360488800798698, -0.22298066223219382], [-0.09546380497381031, -0.08866860018078537], [0.029896123788976367, -0.10081490139792643], [-0.09493187650362522, -0.0078043508936891], [-0.21076886830808403, 0.45567277273550155], [-0.12303681517110253, -0.05108015225825407], [0.07469717593723543, -0.11228152133563582], [0.5947508332026333, 0.21588077071863734], [-0.10870580744896648, -0.1513503405668154], [-0.08356047354412158, 0.11284097989096754], [-0.09657373586303422, -0.21589185219208], [-0.0506151934706682, -0.339445817645953], [-0.07175507801076082, -0.06651727509431667], [0.008943821895630354, -0.08497654183786098], [-0.1087058074489665, -0.1513503405668154], [-0.09545061623281982, -0.06628707727125276], [-0.12516379982454034, -0.034175893409573485], [-0.11523684887518605, -0.008701037522590488], [-0.17536595654468357, 0.5360825663045121], [-0.17536595654468365, 0.5360825663045121], [-0.16261343440647455, 0.4439700188855954], [-0.09210844256778558, 0.049248319267324564], [-0.09543866555157351, 0.0499176760007965], [-0.08891958319079712, 0.04557302979206468], [-0.03816952336861682, -0.1119368414468306], [-0.12214959572013558, -0.010598505212340438], [-0.04775269252569938, -0.11520554186999407], [-0.0835852719170874, 0.5263295059978612], [-0.039216984367689854, -0.11678860656719997], [-0.10525170492027608, 0.1756266001913818], [-0.07282658494847785, -0.22741101813509831], [-0.1251185356778328, -0.1556817158046111], [0.2437863442768604, 0.11619932297175162], [-0.09187093612880828, 0.02932137339818053], [-0.10443960458567873, 0.06216005502350786], [-0.16822232801012665, 0.3808437469933286], [-0.08005073586492858, 0.0663230562842798], [-0.11330299783230699, -0.15428356869833562], [-0.05705262551759115, -0.30509362877735374], [-0.08618886102424125, 0.13305188088888906], [0.6355186445607468, 0.005168544107673091], [0.7743535206282145, -0.0800316461984685], [0.4173927827199395, -0.04236383955396936], [0.71506549507598, -0.10431073730256865], [-0.06939220758403612, -0.12224266337564357], [-0.08432378030687969, -0.06648903478004169], [-0.11330299783230693, -0.15428356869833576], [-0.08630323401987747, -0.11699305539250862], [-0.02179585265157594, -0.2899871415663814], [0.32632199690626457, 0.36893761425915694], [0.4538765865809893, 0.2807583750722457], [-0.0964844829409978, 0.029921792832450073], [-0.1399574288465819, 0.13810596944588777], [0.6835381107205909, -0.07057017052292087], [0.7302469646278138, 0.0691210389768199], [-0.09060468878350333, 0.10352275179875504], [0.6895934638092436, -0.16441377097970084], [-0.03548859719155889, -0.09221175973127024], [-0.105251704920276, 0.17562660019138177], [-0.09208321913152809, -0.17836293923188254], [-0.20139647121090978, 0.6766069510948846], [-0.1479508057806757, 0.34899243162967397], [-0.17050849074821467, 0.45849460790470614], [-0.08358527191708742, 0.5263295059978613], [-0.10617374190240998, -0.048089298811109], [-0.02261875797695372, -0.05688718102191002], [-0.12926118666513411, -0.07571138445097629], [-0.0008171648004735801, -0.06788772733711064], [-0.08957200309419978, 0.08525395287656129], [-0.04650483476473082, -0.05390457770629112], [-0.07701351549043492, 0.14194523058608333], [-0.11861161143762271, -0.11589398143117365], [-0.08794675374543778, 0.07002078319517595], [-0.09220756553219878, 0.050602261525988644], [0.7045522044021921, 0.2784168052583952], [-0.10656978516320055, 0.052903132998516754], [0.7045522044021922, 0.27841680525839524], [0.7045522044021922, 0.27841680525839524], [-0.09101237185799595, 0.09209052079244932], [-0.12043995800400602, 0.01422682742676336], [0.01712307057999428, 0.10232630416452013], [-0.09414642750543399, -0.021918995452943613], [-0.08278090438070876, 0.0773037382073881], [0.30616718854934655, 0.0012406372013222377], [-0.0659243732370409, -0.09492799813832493], [-0.07839960833753436, -0.19739056645473776], [-0.08904678916024408, -0.050185264944005416], [-0.08243620588887964, -0.015559858724626379], [-0.17034628364311002, 0.1904928612444531], [-0.07868726677739138, -0.03407793941013253], [-0.11635513166282702, 0.12262847906023745], [-0.07688540575835495, 0.1158132654047259], [-0.1342422274628025, 0.06087211623705313], [0.7735441987928864, 0.270335465601552], [0.8069829116565443, 0.11716714061509095], [-0.025583947144065464, -0.3509410091161083], [-0.10718185167941129, -0.06949656513505865], [0.007700126164142015, -0.1583448734590568], [-0.09546380497381031, -0.08866860018078536], [0.21175637076687379, -0.29612256672049014], [0.6988893557780519, 0.05582709769867708], [0.013766150339171137, -0.24578335284767344], [-0.14587866623254517, 0.1512248308982449], [-0.00724509912790304, -0.259077444693641], [-0.053440350818153924, -0.12146259540453364], [-0.07896939382744605, -0.06267148582937929], [-0.11571708498923118, 0.06145799897899285]]}, "height": 1080.0, "plugins": [{"type": "reset"}, {"type": "zoom", "enabled": false, "button": true}, {"type": "boxzoom", "enabled": false, "button": true}, {"hoffset": 0, "id": "el22918139732732171992", "location": "mouse", "type": "tooltip", "voffset": 10, "labels": ["Hi for the take a look as we bring nodes back online after the Kilian", "did find one node which had unmounted the and I disabled that I would have expected some kind of not message or something", "Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine On Jun at Alex Chekholko A number of compute nodes on are down with hardware so these jobs have I will purge them from the output in a few ACTIVE JOBNAME USERNAME STATE PROC REMAINING STARTTIME rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May rhiju Running Tue May Running Wed May Running Wed May Running Wed May rhiju Running Wed May Running Wed Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun kappel Running Thu Jun Running Fri Jun Alex Chekholko", "forced the deletion of the problematic I rebooted a couple of the nodes including and they are down with some hardware", "please let us know if you need anything", "Hi rebooted that node and another Please let us know if you have any other", "Hi Thank you for your I relaunched some I still see my jobs from before running and all the new in the I know if there are no more nodes available should get instead of but at least the queue is let you know if I experience anything weird going Johan", "Thank you this is much Kilian", "Hi The accounts have been removed from both and and the associated data Kilian", "Hi the filesystem is full on despite the numerous warnings sent in the As a jobs will fail and application will generate errors until the situation is rules are in place to make sure usage is equally shared between groups and and prevent situation where a single user could monopolize the whole Kilian", "that was Things are looking Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Mark you have emailed me times about Can you I said I am not having issues", "the problem is that the most recent GCC version that the distribution provides is There is also a version you can try in if it work I would suggest trying to compile a newer GCC in your home Kilian", "I will not be monitoring consistently through the Please expect delays in response until Rhiju Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Hi Thanks for your patience while resolving The filesystem is back in finishing troubleshooting a few compute Filesystem access should be working normally from the login Please let us know if you notice any Kilian", "Hi The filesystem on experienced some We believe they are resolved so you should be able to log in without any Please let us know if you still experience any Kilian", "Hi We think the issue was that the filesystem was mostly full in terms of inodes such as files or As a any process creating a lot of small such as a was generating a huge load on the metadata which was in turn struggling to allocate new objects in a very constrained That load very likely was the reason why the filesystem seemed really slow at Some cleanup had been done on the filesystem still need to be so if you have files that you really need on please hesitate to remove and we think that the issue should be solved for Kilian", "Hi We think the issue was that the filesystem was mostly full in terms of inodes such as files or As a any process creating a lot of small such as a was generating a huge load on the metadata which was in turn struggling to allocate new objects in a very constrained That load very likely was the reason why the filesystem seemed really slow at Some cleanup had been done on the filesystem still need to be so if you have files that you really need on please hesitate to remove and we think that the issue should be solved for Kilian", "Thank you very much for your Kalli", "Thanks very Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Things are getting progressively better we were quite anxious over the weekend many thanks for your Rhiju Das Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Hi thanks for the I have been doing calculations and everything has been I guess I should not have been trying to do calculations over Paul Ruijgrok Postdoctoral Scholar in Bryant Molecular Motors Lab email lab phone Web Mailing and visiting Stanford University Department of Bioengineering VIA ORTEGA BioEngineering CA", "I can kill them thanks Zheng", "Hi this is more information about is available at Kilian", "connected thank you so Paul Paul Ruijgrok Postdoctoral Scholar in Bryant Molecular Motors Lab email lab phone Web Mailing and visiting Stanford University Department of Bioengineering VIA ORTEGA BioEngineering CA", "Paul Ruijgrok Postdoctoral Scholar in Bryant Molecular Motors Lab email lab phone Web Mailing and visiting Stanford University Department of Bioengineering VIA ORTEGA BioEngineering CA", "We have an easy way to roll that software out on so just do it on the login node Please let us know if you have any Alex", "Hi find your compiled version in Please give it a try and let us know how it Kilian", "you should probably remove About the temporarily you had thousands of processes running on the login probably a fork loop gone I killed You should be able to connect Kilian", "Hi how come you set But you request only cores from the So this job runs iterations of an osprey Or it launcher simultaneous instances of Alex", "Sorry for the feel free to drop those I rebooted a couple of compute nodes that ended up in a weird state and also contacted the Alex", "seeing this same problem again on Would it be possible to try restarting the scheduler Kalli", "Hi Sorry for the I changed our script to restart the scheduler twice a day instead of once a see what happens It is set to automatically restart at and at Alex", "I am out of town with family and will not be monitoring consistently through the end of Please expect delays in response until Rhiju Associate Professor Departments of Biochemistry and Physics Stanford University School of Medicine", "Thank Sabina Sood Stem Cell Biology Candidate Gerald Crabtree Lab Stanford Medical School", "Hi Thank I am able to log in through sherlock and then which works well for Han Han Institute of Candidate in Biological", "HI Thanks for much I guess go the hard reset Kilian", "Hi Your group is actually pretty good on that your aggregated usage is about which is far less than the biggest individual And by the there is not much alternatives in terms of storage as on and are actually the same Kilian", "I disabled and rebooted that sorry for the Alex", "I appreciate your help resolving this The program runs Matias", "Hi On as a member of an owner you would be able to submit jobs to the partition and effectively get access to every single node on Sherlock as of which is way more than a all jobs submitted to the owners partition are subject to That if the owners of the nodes your jobs are running on needs their your jobs will be killed and Some applications can resume from where they left some and need some cleanup to be able to but besides some this could be a great way to get access to massive amounts of computing Kilian", "Hi Sorry for the I see there was a problem with the scheduler on I restarted it and job reporting is OK I see a job for you either running or so maybe your job already Please let us know if you have any other Alex", "Thank Amanda Miguel Sent with Airmail", "We resolved the issue with the filesystem on Please let us know if you encounter any other Alex", "I rebooted that Please let us know if you see any other", "Sorry about this and for the I am on it and should be able to delete at least some of the stuff on here Steven On Apr at Kilian Cavalotti Hi currently the top user in terms of storage space used in the with more than If you could please do some cleanup and remove files you need that would be Kilian", "Hi I restarted the Please try Sorry for the Alex", "Hi I went ahead and disabled that node and will reboot it and take a closer Please let us know if you have any other Alex", "Hi I see there are a lot of jobs on the but I see any jobs from Are you still having any Alex", "Hi I created your account on You can find more info Please let us know if we can be of any more Alex", "Hi Jupyter is a so I think most people install and update it I can recommend the Anaconda python distribution which installs into your homedir and updates And require any sysadmin So I recommend you use Please let us know if we can be of any more Alex", "thanks very much it does appear to be working Joe", "Hi Not sure about your login but it looks like been able to log in since through another If you even ping something is wacky about either your local DNS or your local network If you still have connectivity problems let me know the host from which connecting and we can figure it Please let us know if we can be of any more Alex", "I just killed the it send emails Cheers Kilian", "Hi It looks like is not available for our older version of We currently have any plans to upgrade on Sorry for the Please let us know if we can be of any more Alex", "Hi take a That cluster is overdue for so some nodes are misbehaving Alex", "I Vijay Sent from my Sorry for the brevity or unusual", "Let me know if you still encounter Kilian", "Hi It would indeed be better to submit a job to do You can launch an interactive job in a session if you want to be able to interact with your Something qsub waiting for job to start job ready This you can detach your screen session and reconnect to it later with on the login Kilian", "I Thanks very much for the Wen", "Hi Do you have a way to break up your jobs into smaller chunks so that they finish in under I think it was the cluster PIs who wanted to bump down the time I see we sent a note to on June Dear Due to the recent trend of increasing wait times in scheduler modified some in order to lower the barrier of entry for users who constantly submit As of the following modifications come into the maximum number of CPUs any given user can use at once is the default walltime limit for jobs is and the maximum that can be requested is a new QOS is introduced that could allow to exceed the CPUs limit when the cluster is This QOS makes jobs meaning that they can be killed and requeued if resources are requested from other To use that one can use the submission as The immediate effect will be that more resources should be kept available for monitor the state of the queue for the next few days to see if the situation improves and if adjustments are Kilian", "Let us know if we can be of any more Kilian", "Hi Your account on has been You can SSH with your SUNetID credentials to Check out the wiki page for more Kilian", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy DNS On November the legacy DNS service will be Please update the DNS configuration on your node or nodes to use the anycast DNS service as described Here is a list of your nodes that queried the legacy DNS service on Monday", "maybe the previous email stream ending and the last emails being Kilian", "Hi Sorry about a couple of nodes crashed and I forgot to disable them before rebooting and your jobs got sent to them immediately as they came but before they mounted the shared So the jobs errored Please resubmit and Alex", "Sorry about a few nodes and we rebooted them go do that Alex", "Hi the limit on the maximum number of CPUs per user was applied to all including the background That should be fixed Note that still a limit on the number of CPUs usable with the background so we can still keep resources available for but much higher than in the default So I believe the problem is fixed And I think the job defaulting to the NORMAL QOS Please try and let me know if you still see any Kilian", "No Let me know if you notice anything unexpected under the new Kilian", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy DNS On November the legacy DNS service will be Please update the DNS configuration on your node or nodes to use the anycast DNS service as described Here is a list of your nodes that queried the legacy DNS service on Monday", "Note that disk the whole filesystem goes I suggest we do this by CPU usage not file system usage since there will be no CPU usage a Vijay Sent from my Sorry for the brevity or unusual", "Hi was efficient or and I have the It ran with and one process per did not produce any out put after more than I killed It ran without and one process per node So far I understand I should run with less processes per even if this is not and use Thank Yana Yana Gofman Postdoctoral Fellow Michael Levitt Lab Department of Structural Biology Stanford University School of Medicine James Clark Center Campus Room CA", "Hi This is indeed what I eventually did but I also had to do Not sure but it did not work thought that if I ask each process uses of it should be and fits the machine but somehow it did not work this thank you very Yana Yana Gofman Postdoctoral Fellow Michael Levitt Lab Department of Structural Biology Stanford University School of Medicine James Clark Center Campus Room CA", "Hi No Thanks for your effort and for your this is much Kilian", "Hi Thanks for your effort and for your this is much Kilian", "Hi Thanks a lot for your effort and your this is much Kilian", "Hi a few days is perfectly We just want to make sure that all the and obsolete files are cleaned up so room can be made for more useful Kilian", "Hi for getting back to and for your cooperation in that can keep as much as you We just want to make sure that all the and obsolete files are cleaned up so room can be made for more useful Kilian", "Hi Those failures were caused by the local disk being full on some of the compute I did some cleanup so it should be better And I believe the errors you had on were caused by the same Kilian", "I ended up just killing old processes from people not logged in that are more than a week Alex", "Just running basic commands seemed abnormally but now working much Erik Erik Postdoctoral Scholar Gerald Crabtree Lab Stanford University", "Hi I think usually that means that the kernel killed that usually because it used up all the system Do you know how much memory your program Perhaps the memory usage varies with input data or some Alex", "Should be back in business Kilian", "Hi I power cycled look for them to come back up in a couple of Alex", "Hi I restarted the it should come back Kilian", "Some of the nodes I rebooted them and your old jobs Consider requesting more memory for your in case they ran out of Alex", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still attempting to use the legacy NTP service even though been turned Please consider updating the NTP configuration on your nodes to use the current NTP service as described Make sure to restart the NTP process reboot the so it uses the new Here is a list of your nodes that need to be updated", "Hi I created your account on You can connect the the login node with Please see for more Kilian", "I found the following on the Out of Kill process process UID So you could try to reduce the total number of processes as well as the number of processes per Kilian", "Hi not completely but quite Definitely very rebooted it should come back online Kilian", "Hi Thanks for the The Maui scheduler That should be better Kilian", "Hi not sure what you mean by Your state is which means eligible to run and will start as soon as enough resources are Kilian", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy NTP service that was replaced years On May the systems providing the legacy NTP service will no longer respond to NTP Please update the NTP configuration on your nodes to use the current NTP service as described Here is a list of your nodes that need to be", "Hi Looks like you submitted a bunch of jobs with small resource they all ended up scheduled to the same physical and that node crashed after maybe running out of I went ahead and rebooted that Maybe adjust your resource requests per job up a Please let us know if we can be of any more You can use the command to see your Alex", "Hi Thanks for the Alex was able to provide what we", "I created the vineetk account on Check out the wiki link for more Alex", "Hi I created your account on You can SSH with your SUNetID Check out the wiki link in the motd for more Please let us know if we can be of any more Alex", "I added the account for enf on More info at the wiki and in the Alex", "Hi I created your account on You can SSH to with your SUNetID a link to the wiki in the Please let us know if we can be of any more Alex", "I removed many TBs Hopefully this is enough Matt Original Message Computing March AM Filesystem usage on Hi currently using about on which makes you the largest consumer of storage resources on that Since the filesystem starts to fill we would appreciate if you could do some cleanup in your old remove the ones you need and maybe transfer out the ones you want to keep on the longer Please let me know if you have any Research Computing Support", "Thanks for the clean some stuff up over the On March Research Computing Support Hi currently using on which makes you the largest consumer of storage resources on that Since the filesystem starts to fill we would appreciate if you could do some cleanup in your old remove the ones you need and maybe transfer out the ones you want to keep on the longer Please let me know if you have any Research Computing Support Sent from my", "You are receiving this message because you are listed in NetDB as the administrator for a node or nodes that are still using the legacy NTP service that was replaced years On May the systems providing the legacy NTP service will no longer respond to NTP Please update the NTP configuration on your nodes to use the current NTP service as described Here is a list of your nodes that need to be", "Thanks for the Will keep it in mind in the Steven On Feb at Alex Chekholko Looks like a lot of these jobs are so likely they are running slower than you sryckbos Ss sryckbos S sryckbos Dl worker sryckbos Dl worker sryckbos Rl worker sryckbos Dl worker sryckbos Dl worker sryckbos Dl worker On Alex Chekholko I was looking around at some compute and I see your osprey jobs sometimes run out of memory and get Out of Kill process score or sacrifice child Killed process UID You may want to request more memory for those Alex Chekholko", "Hi I took a look at that jobid and it looks like there is some minor problem with one compute disabled that compute node and will take a closer Please let us know if you see any other Alex", "Hi Your account on has been Kilian", "Hi I created your account on Kilian", "Hi GCC is installed on node You can use it scl enable bash posixgcc version Hat Kilian", "Thanks working great Nir Nir of Biological Chemistry The Silberman Institute of Life Sciences The Hebrew University of Jerusalem Lab", "Hi I created your account on You can SSH with your SUNetID credentials to Check out the wiki page for more Please let us know if you need anything Alex", "Hi I created your account on You can SSH to with your SUNetID so your username is Check out the wiki for more Alex", "Hi Matlab is not installed on You can use it on Farmshare see for Kilian", "I created your account on Check out the wiki for more Please let us know if you have any Alex", "Accounts are always mapped to On we use Unix groups to group people by their Alex", "Hi I restarted those they should come back Kilian", "Hi I see you have two jobs listed and each is on a crashed nodes and go reboot those and you should see those jobs Alex", "Hi Thanks for letting me Kilian", "Hi Reboot is thanks for reporting Kilian", "Hi Thanks for the the reboot is Kilian", "No On we have and Kilian", "Hi I took the example of job It runs on as well as job ids to all of which are Those processes seem indeed all be stuck on something as they use any CPU time at all on the Looking in more it looks like stuck on some sort of the backtrace for one of gstack in from in from in from in fork from in from in from handler in from in malloc from in in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in mkplan in mkplan in in in in in in in in in main From that trace it looks like the process received a signal forked and then is now waiting on a Does that sound familiar to you regarding the Do you now what kind of signal the application may have Kilian", "Hi This fixed our are not using python scripts in the jobs but they may otherwise make use of the abrt socket check the source Rosetta And abrt adds a new exception handler that overrides the default See let the rest of my lab know that fixed the And as per your other send a note to the mailing Kilian", "Hi Thanks for the detailed Looking at your idle processes on that specific it looks like they were stuck on connecting to the abrt abrt is a to help users to detect defects in applications and to create a bug report with all informations needed by maintainer to fix I think you were using it on purpose me if but since it provides python bindings which may be active by likely that the python scripts in your jobs were using there seems to be a bug with so I removed it from the compute And it looks like it even unblocked your previously idle Let me know if it really fixes your Kilian On Rhiju Das Hi Thanks for helping set up the two new users from my lab so We had one more question seen this in the but now its getting a little I will often kick off and see them as running but then they never actually use any CPU time or do After the wall time is they are This has not been mission critical for the last few but is about to be a big pasting below an example of such a zombie job running right now On the same node there are four other jobs from me that are running fine which I can see via but this and its sisters are not going No one else seems to be running on that I tried to reduce the declared memory to the default of but that Any advice would be We want to be the ones tying up the queue with zombie Rhiju qstat Job R queue SP server Checkpoint u ctime Fri Sep n n n n mtime Fri Sep Priority qtime Fri Sep Rerunable True etime Fri Sep Fri Sep False", "No Let me know if it changes things for Kilian", "Hi Nice to Regarding I think it can be used on without a But installed and licensed on Farmshare and Kilian", "Hi The memory usage of a job at some point in time is not always representative of its peak So maybe on the nodes the jobs were not using all the memory they requested at that specific but perhaps they will need it gonna check with the see if intended an what his real usage Kilian", "Hi The NVIDIA kernel module was not loaded correctly on that It should be fixed Kilian", "Hi I restarted the and it looks like the runaway jobs have Regarding the high number of jobs as Alex explained due to the nature of the jobs currently If you run see that most nodes that have cores available have very little memory in any case not enough to run the jobs that are There are a few nodes for which the scheduler state does not match their real load probably because of runaway gonna take care of but it change much regarding the pending Kilian", "Hi The node crashed and failed to remount the directory at fixed Kilian", "Hi has been rebooted and should be back online And I deleted your Kilian", "Hi account has been You can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "Hi was indeed overloaded with user processes and partially rebooted the it should come back online Kilian", "Hi account has been You can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "Hi Your account has been can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "No And sorry we have a more recent Kilian", "Erik Miller Candidate Department of Genetics Gerald Crabtree Lab Stanford University", "Thanks you should be able to log in with your normal Stanford username and with ssh Here is the wiki for During our next go over how to submit jobs on this awesome Best Alexandre Alexandre Colavin Biophysics PhD Candidate Huang Lab Stanford University", "Hi We do not handle the billing for use of that is managed through the I would recommend you contact Levitt and To my only the PIs who are entitled to use the I do not see Weis in that Pande Levitt Altman Huang Das Bryant Crabtree Guibas Covert Darve Martinez Kornberg When did you get an Were you working with another Ruth", "Hi Glad you found a way around the Just out of what the issue Kilian", "Dear Many I have logged on Phil Original Message June PM account Hi I created an account for try logging in Check out the wiki for more Please let us know if we can be of any more Alex On Philip Robinson Dear I am a research associate in the Kornberg group in structural biology and would like to request a user account on the Are you the correct guy to deal with Thanks in Phil Robinson", "I restarted the scheduler and Must be some bug in our version but been putting off any upgrades because likely we should do a full as all software on this cluster is getting Alex", "Hi It could well be that the compute nodes the jobs have a smaller set of packages tends to be graphical so maybe installed on the login node for but not on the compute Try a to get an Interactive shell on a compute Alex", "Hi mixtape in pypi it looks If it changes really fast maybe its better to install in your or is there a particular version I should", "using files to share data between MPI ranks on a single and when persisted on the lustre much slower than simply copying the data between the On getting good performance", "Part of the scheduler was down It is now running Thanks for the Will", "Hi I thought I sent this out my It was stuck in draft in this I deleted all your stuck I also rebooting those Will", "I think those jobs are terminated so it should get Kilian", "No glad you found the because I really find anything wrong with the Kilian", "Hi restarted the MDS Can you please take a look now and see if the login node responds also stopped your Could you please try to submit less jobs at a to see if it makes a Like submit one or and see how long they take to Then launch and Thanks Kilian", "Hi I created you account on You can SSH to with your SUNetID Check out the wiki for more feel free to Kilian", "Hi I created your account on You can SSH to with your SUNetID Check out the wiki for more feel free to Alex", "that seems to have fixed the problem my jobs are running without On Mar at Alex Chekholko Hi I rebooted those four nodes and I see anything wrong with works Try Or else let us know how to reproduce your Alex On Alex Chekholko Hi take a look I see all four nodes with GPU are reboot them and see if I see anything Alex On Jeffrey Weber Hi Do you know if anything has changed in the GPU configuration on in recent been successfully running OpenCL jobs for but I now receive a which seems to indicate that the cluster now has no OpenCL capable", "Hi There indeed seems to be a problem with some of the We took them offline and rebooted and now the pending jobs have started to flow investigating the source of the Sorry for the Kilian", "Hi I ran pbsnodes take a Alex", "Vijay Sent from my Sorry for the brevity or unusual", "Hi We have a wiki but it has very little running regular Please let us know if you have any happy to answer by We also have weekly office Alex", "Hi I created your account on You can SSH with your SUNetID credentials to Please see the wiki for more Alex", "Hi I see a blas installed on the login rpm blas I also installed that blas RPM on the compute Please let us know if we can be of any more Alex", "Thanks Yeah i was looking for a file in but good to know one in the Thanks Emma Emma Chory Chemical Engineering Candidate Crabtree Research Laboratory Stanford University", "Hi The useful queues on are called and Are you explicitly specifying as a queue Try just leaving that parameter your job will get routed looking at and Please let us know if we can be of any more Alex", "I noticed that and spent a few mins leaving it down and looking for but in the just restarted look more carefully through the Alex", "Your mail to with the subject queue Is being held until the list moderator can review it for The reason it is being Post by to a list Either the message will get posted to the or you will receive notification of the If you would like to cancel this please visit the following", "Hi So back in November you had prepared a list of things to on But I requested that backups be done before any If those things been revisit that list and add the scheduler upgrade to it as estimate the total downtime required and talk about when this could be Thanks Ruth"]}], "id": "el22918139732724253696", "width": 1080.0, "axes": [{"ydomain": [-0.6000000000000001, 0.8], "id": "el22918139732688785592", "zoomable": true, "texts": [{"zorder": 3, "text": "BioX3 Ticket Groupings", "id": "el22918139732732122616", "rotation": -0.0, "v_baseline": "auto", "alpha": 1, "h_anchor": "middle", "coordinates": "axes", "fontsize": 20.0, "color": "#000000", "position": [0.49999999999999994, 1.0059737156511348]}], "sharey": [], "yscale": "linear", "axes": [{"scale": "linear", "fontsize": 10.0, "tickformat": null, "tickvalues": null, "position": "bottom", "grid": {"gridOn": false}, "nticks": 9, "visible": true}, {"scale": "linear", "fontsize": 10.0, "tickformat": null, "tickvalues": null, "position": "left", "grid": {"gridOn": false}, "nticks": 10, "visible": true}], "sharex": [], "lines": [], "xdomain": [-0.4, 1.0], "markers": [], "collections": [{"edgewidths": [1.0], "zorder": 1, "pathcoordinates": "display", "id": "el22918139732732171992", "facecolors": ["#0FA2EF", "#7F00FF", "#2ADCDC", "#7F00FF", "#FF562B", "#FF562B", "#FF562B", "#0FA2EF", "#0FA2EF", "#FF0000", "#62FAC3", "#FF0000", "#FF562B", "#62FAC3", "#9CFAA3", "#FF562B", "#9CFAA3", "#9CFAA3", "#7F00FF", "#62FAC3", "#62FAC3", "#62FAC3", "#FFA256", "#0FA2EF", "#62FAC3", "#62FAC3", "#FF562B", "#FF562B", "#0FA2EF", "#2ADCDC", "#FFA256", "#2ADCDC", "#2ADCDC", "#62FAC3", "#62FAC3", "#62FAC3", "#0FA2EF", "#0FA2EF", "#7F00FF", "#9CFAA3", "#FF0000", "#2ADCDC", "#9CFAA3", "#FF562B", "#FF562B", "#0FA2EF", "#2ADCDC", "#7F00FF", "#FF0000", "#4756FB", "#FF562B", "#62FAC3", "#FF562B", "#0FA2EF", "#FF562B", "#FFA256", "#2ADCDC", "#FF562B", "#2ADCDC", "#62FAC3", "#FF0000", "#FF562B", "#D4DC7F", "#7F00FF", "#0FA2EF", "#FF0000", "#2ADCDC", "#2ADCDC", "#FF562B", "#7F00FF", "#9CFAA3", "#FFA256", "#7F00FF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#7F00FF", "#9CFAA3", "#62FAC3", "#FFA256", "#0FA2EF", "#FFA256", "#0FA2EF", "#FFA256", "#7F00FF", "#4756FB", "#FFA256", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#7F00FF", "#2ADCDC", "#62FAC3", "#4756FB", "#D4DC7F", "#4756FB", "#D4DC7F", "#9CFAA3", "#9CFAA3", "#7F00FF", "#FFA256", "#7F00FF", "#4756FB", "#4756FB", "#FF562B", "#62FAC3", "#D4DC7F", "#D4DC7F", "#0FA2EF", "#4756FB", "#FFA256", "#0FA2EF", "#FF0000", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#0FA2EF", "#2ADCDC", "#FF562B", "#FFA256", "#FF562B", "#0FA2EF", "#2ADCDC", "#0FA2EF", "#FF0000", "#0FA2EF", "#0FA2EF", "#D4DC7F", "#0FA2EF", "#D4DC7F", "#D4DC7F", "#0FA2EF", "#62FAC3", "#62FAC3", "#7F00FF", "#0FA2EF", "#4756FB", "#FFA256", "#FFA256", "#FF562B", "#FFA256", "#2ADCDC", "#9CFAA3", "#FF0000", "#0FA2EF", "#0FA2EF", "#D4DC7F", "#D4DC7F", "#FFA256", "#FF0000", "#FFA256", "#2ADCDC", "#FF562B", "#D4DC7F", "#FF562B", "#62FAC3", "#2ADCDC", "#2ADCDC", "#7F00FF", "#2ADCDC"], "pathtransforms": [[4.47213595499958, 0.0, 0.0, 4.47213595499958, 0.0, 0.0]], "offsets": "data01", "xindex": 0, "alphas": [null], "edgecolors": ["#000000"], "yindex": 1, "offsetcoordinates": "data", "paths": [[[[0.0, -0.5], [0.13260155, -0.5], [0.25978993539242673, -0.44731684579412084], [0.3535533905932738, -0.3535533905932738], [0.44731684579412084, -0.25978993539242673], [0.5, -0.13260155], [0.5, 0.0], [0.5, 0.13260155], [0.44731684579412084, 0.25978993539242673], [0.3535533905932738, 0.3535533905932738], [0.25978993539242673, 0.44731684579412084], [0.13260155, 0.5], [0.0, 0.5], [-0.13260155, 0.5], [-0.25978993539242673, 0.44731684579412084], [-0.3535533905932738, 0.3535533905932738], [-0.44731684579412084, 0.25978993539242673], [-0.5, 0.13260155], [-0.5, 0.0], [-0.5, -0.13260155], [-0.44731684579412084, -0.25978993539242673], [-0.3535533905932738, -0.3535533905932738], [-0.25978993539242673, -0.44731684579412084], [-0.13260155, -0.5], [0.0, -0.5]], ["M", "C", "C", "C", "C", "C", "C", "C", "C", "Z"]]]}], "axesbg": "#FFFFFF", "ylim": [-0.6000000000000001, 0.8], "images": [], "bbox": [0.125, 0.125, 0.775, 0.775], "xscale": "linear", "xlim": [-0.4, 1.0], "paths": [], "axesbgalpha": null}]});
            })
         });
}
</script>